from openai import AsyncOpenAI
import asyncio
import json
import os
from enum import Enum
from typing import Any, List, Dict, Optional
from pydantic import BaseModel, Field
import streamlit as st

# ê¸°ë³¸ ëª¨ë¸ ì •ì˜
class Role(str, Enum):
    """Role enum for chat messages"""
    user = "user"
    assistant = "assistant"
    system = "system"

class ChatMessage(BaseModel):
    """Single chat message used in few-shot examples"""
    role: Role
    content: str

class Issues(BaseModel):
    """Structured output returned by checkers."""
    has_issues: bool
    issues: List[str]
    severity: str = "medium"  # low, medium, high
    category: str = "general"  # general, clarity, specificity, instruction_following, etc.

    @classmethod
    def no_issues(cls) -> "Issues":
        return cls(has_issues=False, issues=[], severity="low", category="general")

class PromptAnalysis(BaseModel):
    """í”„ë¡¬í”„íŠ¸ ë¶„ì„ ê²°ê³¼"""
    clarity_score: float  # 0-10
    specificity_score: float  # 0-10
    instruction_following_score: float  # 0-10
    overall_score: float  # 0-10
    recommendations: List[str]
    strengths: List[str]
    weaknesses: List[str]

class OptimizedPrompt(BaseModel):
    """ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ê²°ê³¼"""
    original_prompt: str
    optimized_prompt: str
    changes_made: List[str]
    improvement_explanation: str
    estimated_improvement: float  # percentage

class UserFeedback(BaseModel):
    """ì‚¬ìš©ì í”¼ë“œë°±"""
    feedback_text: str
    feedback_type: str = "general"  # general, specific_issue, improvement_request
    priority: str = "medium"  # low, medium, high
    category: str = "general"  # clarity, specificity, instruction_following, agentic_capabilities, format, other

class FeedbackAnalysis(BaseModel):
    """í”¼ë“œë°± ë¶„ì„ ê²°ê³¼"""
    understood_feedback: str
    feedback_category: str
    required_changes: List[str]
    revision_strategy: str
    estimated_impact: float  # 0-10

class RevisedPrompt(BaseModel):
    """í”¼ë“œë°± ê¸°ë°˜ ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸"""
    original_optimized_prompt: str
    user_feedback: str
    revised_prompt: str
    changes_made: List[str]
    feedback_addressed: List[str]
    improvement_explanation: str

# Agent êµ¬í˜„
class Agent:
    def __init__(self, name: str, model: str, output_type: type, instructions: str):
        self.name = name
        self.model = model
        self.output_type = output_type
        self.instructions = instructions

class Runner:
    @staticmethod
    async def run(agent: Agent, input_data: str, progress_callback=None):
        if progress_callback:
            progress_callback(f"ğŸ” Agent '{agent.name}' ì‹¤í–‰ ì¤‘...")
        
        class Result:
            def __init__(self, final_output):
                self.final_output = final_output
        
        # GPT-4.1 ê°€ì´ë“œ ê¸°ë°˜ ë¶„ì„ ë¡œì§
        if agent.name == "clarity_checker":
            return await Runner._analyze_clarity(agent, input_data, progress_callback)
        elif agent.name == "specificity_checker":
            return await Runner._analyze_specificity(agent, input_data, progress_callback)
        elif agent.name == "instruction_following_checker":
            return await Runner._analyze_instruction_following(agent, input_data, progress_callback)
        elif agent.name == "agentic_capability_checker":
            return await Runner._analyze_agentic_capabilities(agent, input_data, progress_callback)
        elif agent.name == "prompt_optimizer":
            return await Runner._optimize_prompt(agent, input_data, progress_callback)
        elif agent.name == "few_shot_optimizer":
            return await Runner._optimize_few_shot(agent, input_data, progress_callback)
        elif agent.name == "feedback_analyzer":
            return await Runner._analyze_feedback(agent, input_data, progress_callback)
        elif agent.name == "prompt_reviser":
            return await Runner._revise_prompt_with_feedback(agent, input_data, progress_callback)
        
        return Result(agent.output_type.no_issues() if hasattr(agent.output_type, 'no_issues') else {})

    @staticmethod
    async def _analyze_clarity(agent: Agent, input_data: str, progress_callback=None):
        if progress_callback:
            progress_callback("ğŸ“‹ ëª…í™•ì„± ë¶„ì„ ì¤‘...")
        
        class Result:
            def __init__(self, final_output):
                self.final_output = final_output
        
        issues = []
        
        # ëª…í™•ì„± ì²´í¬ ë¡œì§ (GPT-4.1 ê°€ì´ë“œ ê¸°ë°˜)
        if len(input_data.strip()) < 20:
            issues.append("í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ì§§ì•„ ëª…í™•í•œ ì§€ì‹œì‚¬í•­ì„ ì œê³µí•˜ì§€ ëª»í•©ë‹ˆë‹¤")
        
        if not any(keyword in input_data.lower() for keyword in ['you are', 'task', 'goal', 'objective']):
            issues.append("ì—­í• ì´ë‚˜ ëª©í‘œê°€ ëª…í™•í•˜ê²Œ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        if input_data.count('?') > 5:
            issues.append("ë„ˆë¬´ ë§ì€ ì§ˆë¬¸ì´ í¬í•¨ë˜ì–´ í˜¼ë€ì„ ì•¼ê¸°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        ambiguous_words = ['maybe', 'perhaps', 'might', 'could be', 'possibly']
        if any(word in input_data.lower() for word in ambiguous_words):
            issues.append("ëª¨í˜¸í•œ í‘œí˜„ì´ í¬í•¨ë˜ì–´ ìˆì–´ ëª…í™•ì„±ì„ í•´ì¹©ë‹ˆë‹¤")
        
        result = agent.output_type(
            has_issues=len(issues) > 0,
            issues=issues,
            severity="high" if len(issues) > 2 else "medium" if len(issues) > 0 else "low",
            category="clarity"
        )
        
        if progress_callback:
            progress_callback(f"âœ… ëª…í™•ì„± ë¶„ì„ ì™„ë£Œ: {len(issues)}ê°œ ë¬¸ì œ ë°œê²¬")
        
        return Result(result)

    @staticmethod
    async def _analyze_specificity(agent: Agent, input_data: str, progress_callback=None):
        if progress_callback:
            progress_callback("ğŸ¯ êµ¬ì²´ì„± ë¶„ì„ ì¤‘...")
        
        class Result:
            def __init__(self, final_output):
                self.final_output = final_output
        
        issues = []
        
        # êµ¬ì²´ì„± ì²´í¬ ë¡œì§
        vague_instructions = ['do something', 'help me', 'make it better', 'improve']
        if any(instruction in input_data.lower() for instruction in vague_instructions):
            issues.append("ì§€ì‹œì‚¬í•­ì´ ë„ˆë¬´ ì¶”ìƒì ì…ë‹ˆë‹¤. êµ¬ì²´ì ì¸ í–‰ë™ì„ ëª…ì‹œí•´ì£¼ì„¸ìš”")
        
        if not any(keyword in input_data.lower() for keyword in ['format', 'structure', 'example', 'template']):
            issues.append("ì¶œë ¥ í˜•ì‹ì´ë‚˜ êµ¬ì¡°ì— ëŒ€í•œ ëª…ì‹œì  ì§€ì¹¨ì´ ì—†ìŠµë‹ˆë‹¤")
        
        if len(input_data.split()) < 50:
            issues.append("í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ì§§ì•„ ì¶©ë¶„í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ì§€ ëª»í•©ë‹ˆë‹¤")
        
        # GPT-4.1 ê°€ì´ë“œ: ë„êµ¬ ì‚¬ìš© ë° ê³„íš ìœ ë„ ì²´í¬
        if 'tool' in input_data.lower() and 'plan' not in input_data.lower():
            issues.append("ë„êµ¬ ì‚¬ìš©ì´ ì–¸ê¸‰ë˜ì—ˆì§€ë§Œ ê³„íš ìˆ˜ë¦½ì— ëŒ€í•œ ì§€ì¹¨ì´ ì—†ìŠµë‹ˆë‹¤")
        
        result = agent.output_type(
            has_issues=len(issues) > 0,
            issues=issues,
            severity="medium" if len(issues) > 1 else "low",
            category="specificity"
        )
        
        if progress_callback:
            progress_callback(f"âœ… êµ¬ì²´ì„± ë¶„ì„ ì™„ë£Œ: {len(issues)}ê°œ ë¬¸ì œ ë°œê²¬")
        
        return Result(result)

    @staticmethod
    async def _analyze_instruction_following(agent: Agent, input_data: str, progress_callback=None):
        if progress_callback:
            progress_callback("ğŸ“ ì§€ì‹œì‚¬í•­ ì¤€ìˆ˜ ë¶„ì„ ì¤‘...")
        
        class Result:
            def __init__(self, final_output):
                self.final_output = final_output
        
        issues = []
        
        # GPT-4.1ì€ ì§€ì‹œì‚¬í•­ì„ ë” ë¬¸ì ê·¸ëŒ€ë¡œ ë”°ë¥´ë¯€ë¡œ ëª…í™•í•œ ì§€ì‹œê°€ ì¤‘ìš”
        if not input_data.strip().endswith('.') and not input_data.strip().endswith('!'):
            issues.append("ì§€ì‹œì‚¬í•­ì´ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëë‚˜ì§€ ì•Šì•„ ëª¨í˜¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        contradictory_words = [('always', 'never'), ('must', 'optional'), ('required', 'if needed')]
        for word1, word2 in contradictory_words:
            if word1 in input_data.lower() and word2 in input_data.lower():
                issues.append(f"'{word1}'ê³¼ '{word2}'ì™€ ê°™ì€ ìƒì¶©ë˜ëŠ” ì§€ì‹œì‚¬í•­ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
        
        # ìš°ì„ ìˆœìœ„ ì²´í¬
        if 'important' in input_data.lower() and 'priority' not in input_data.lower():
            issues.append("ì¤‘ìš”ë„ëŠ” ì–¸ê¸‰ë˜ì—ˆì§€ë§Œ ìš°ì„ ìˆœìœ„ê°€ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        result = agent.output_type(
            has_issues=len(issues) > 0,
            issues=issues,
            severity="high" if len(issues) > 2 else "medium",
            category="instruction_following"
        )
        
        if progress_callback:
            progress_callback(f"âœ… ì§€ì‹œì‚¬í•­ ì¤€ìˆ˜ ë¶„ì„ ì™„ë£Œ: {len(issues)}ê°œ ë¬¸ì œ ë°œê²¬")
        
        return Result(result)

    @staticmethod
    async def _analyze_agentic_capabilities(agent: Agent, input_data: str, progress_callback=None):
        if progress_callback:
            progress_callback("ğŸ¤– ì—ì´ì „í‹± ëŠ¥ë ¥ ë¶„ì„ ì¤‘...")
        
        class Result:
            def __init__(self, final_output):
                self.final_output = final_output
        
        issues = []
        
        # GPT-4.1 ê°€ì´ë“œì˜ 3ê°€ì§€ í•µì‹¬ ìš”ì†Œ ì²´í¬
        has_persistence = any(keyword in input_data.lower() for keyword in 
                            ['keep going', 'continue', 'persist', 'until complete', 'multi-step'])
        has_tool_guidance = any(keyword in input_data.lower() for keyword in 
                              ['tools', 'function', 'use available', 'do not guess'])
        has_planning = any(keyword in input_data.lower() for keyword in 
                         ['plan', 'step by step', 'think through', 'reflect'])
        
        if not has_persistence:
            issues.append("ì§€ì†ì„±(persistence) ì§€ì¹¨ì´ ì—†ìŠµë‹ˆë‹¤. ë©€í‹°í„´ ì‘ì—…ì—ì„œ ì¤‘ìš”í•©ë‹ˆë‹¤")
        
        if not has_tool_guidance and 'tool' in input_data.lower():
            issues.append("ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ëª…í™•í•œ ì§€ì¹¨ì´ ì—†ìŠµë‹ˆë‹¤")
        
        if not has_planning:
            issues.append("ê³„íš ìˆ˜ë¦½ ë° ë°˜ì„±ì  ì‚¬ê³ ì— ëŒ€í•œ ì§€ì¹¨ì´ ì—†ìŠµë‹ˆë‹¤")
        
        result = agent.output_type(
            has_issues=len(issues) > 0,
            issues=issues,
            severity="medium",
            category="agentic_capabilities"
        )
        
        if progress_callback:
            progress_callback(f"âœ… ì—ì´ì „í‹± ëŠ¥ë ¥ ë¶„ì„ ì™„ë£Œ: {len(issues)}ê°œ ë¬¸ì œ ë°œê²¬")
        
        return Result(result)

    @staticmethod
    async def _optimize_prompt(agent: Agent, input_data: str, progress_callback=None):
        if progress_callback:
            progress_callback("âœï¸ í”„ë¡¬í”„íŠ¸ ìµœì í™” ì¤‘...")
        
        class Result:
            def __init__(self, final_output):
                self.final_output = final_output
        
        try:
            data = json.loads(input_data)
            original_prompt = data.get("original_prompt", "")
            all_issues = data.get("all_issues", [])
            
            # GPT-4.1 ê°€ì´ë“œ ê¸°ë°˜ ìµœì í™”
            optimized_prompt = original_prompt
            changes_made = []
            
            # 1. ì—­í•  ëª…í™•í™”
            if not optimized_prompt.lower().startswith('you are'):
                optimized_prompt = "You are a helpful AI assistant. " + optimized_prompt
                changes_made.append("ëª…í™•í•œ ì—­í•  ì •ì˜ ì¶”ê°€")
            
            # 2. GPT-4.1 ì—ì´ì „í‹± êµ¬ì„± ìš”ì†Œ ì¶”ê°€
            agentic_components = []
            
            # Persistence ì¶”ê°€
            if not any(keyword in optimized_prompt.lower() for keyword in ['keep going', 'until complete']):
                agentic_components.append(
                    "Please keep going until the task is completely resolved, before ending your turn."
                )
                changes_made.append("ì§€ì†ì„±(persistence) ì§€ì¹¨ ì¶”ê°€")
            
            # Tool-calling guidance ì¶”ê°€ (í•„ìš”ì‹œ)
            if 'tool' in optimized_prompt.lower() and 'do not guess' not in optimized_prompt.lower():
                agentic_components.append(
                    "If you are not sure about information needed for the task, use available tools to gather relevant information - do NOT guess or make up an answer."
                )
                changes_made.append("ë„êµ¬ ì‚¬ìš© ì§€ì¹¨ ì¶”ê°€")
            
            # Planning guidance ì¶”ê°€
            if not any(keyword in optimized_prompt.lower() for keyword in ['plan', 'step by step']):
                agentic_components.append(
                    "Plan extensively before taking action, and reflect on the outcomes of your actions."
                )
                changes_made.append("ê³„íš ìˆ˜ë¦½ ì§€ì¹¨ ì¶”ê°€")
            
            # 3. êµ¬ì²´ì  ê°œì„ ì‚¬í•­ ì ìš©
            for issue_set in all_issues:
                for issue in issue_set.get('issues', []):
                    if 'ë„ˆë¬´ ì§§' in issue:
                        optimized_prompt += "\n\nPlease provide detailed, comprehensive responses with clear explanations."
                        changes_made.append("ìƒì„¸í•œ ì‘ë‹µ ìš”êµ¬ì‚¬í•­ ì¶”ê°€")
                    elif 'ëª¨í˜¸í•œ í‘œí˜„' in issue:
                        optimized_prompt = optimized_prompt.replace('maybe', 'specifically')
                        optimized_prompt = optimized_prompt.replace('perhaps', 'exactly')
                        changes_made.append("ëª¨í˜¸í•œ í‘œí˜„ ì œê±°")
            
            # ì—ì´ì „í‹± êµ¬ì„± ìš”ì†Œ ì¶”ê°€
            if agentic_components:
                optimized_prompt += "\n\n" + "\n".join(agentic_components)
            
            # 4. ì¶œë ¥ í˜•ì‹ ëª…ì‹œ
            if 'format' not in optimized_prompt.lower():
                optimized_prompt += "\n\nProvide your response in a clear, structured format."
                changes_made.append("ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ ì¶”ê°€")
            
            result = OptimizedPrompt(
                original_prompt=original_prompt,
                optimized_prompt=optimized_prompt,
                changes_made=changes_made,
                improvement_explanation="GPT-4.1 ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ëª…í™•ì„±, êµ¬ì²´ì„±, ì—ì´ì „í‹± ëŠ¥ë ¥ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.",
                estimated_improvement=min(len(changes_made) * 15, 80)  # ìµœëŒ€ 80% ê°œì„ 
            )
            
            if progress_callback:
                progress_callback(f"âœ… í”„ë¡¬í”„íŠ¸ ìµœì í™” ì™„ë£Œ: {len(changes_made)}ê°œ ê°œì„ ì‚¬í•­ ì ìš©")
            
            return Result(result)
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"âŒ ìµœì í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return Result(OptimizedPrompt(
                original_prompt=input_data,
                optimized_prompt=input_data,
                changes_made=[],
                improvement_explanation="ìµœì í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                estimated_improvement=0
            ))

    @staticmethod
    async def _optimize_few_shot(agent: Agent, input_data: str, progress_callback=None):
        if progress_callback:
            progress_callback("ğŸ“ Few-shot ì˜ˆì œ ìµœì í™” ì¤‘...")
        
        class Result:
            def __init__(self, final_output):
                self.final_output = final_output
        
        try:
            data = json.loads(input_data)
            messages = data.get("messages", [])
            optimized_prompt = data.get("optimized_prompt", "")
            
            # Few-shot ì˜ˆì œ ê°œì„ 
            improved_messages = []
            
            for msg in messages:
                if msg.get("role") == "assistant":
                    content = msg.get("content", "")
                    # ë” êµ¬ì²´ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µìœ¼ë¡œ ê°œì„ 
                    if len(content) < 50:
                        content = f"Based on your request, here's a detailed response: {content}. Let me know if you need further clarification or have additional questions."
                    improved_messages.append({"role": "assistant", "content": content})
                else:
                    improved_messages.append(msg)
            
            if progress_callback:
                progress_callback(f"âœ… Few-shot ìµœì í™” ì™„ë£Œ: {len(improved_messages)}ê°œ ë©”ì‹œì§€")
            
            return Result({"messages": improved_messages})
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"âŒ Few-shot ìµœì í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return Result({"messages": []})

    @staticmethod
    async def _analyze_feedback(agent: Agent, input_data: str, progress_callback=None):
        if progress_callback:
            progress_callback("ğŸ“ í”¼ë“œë°± ë¶„ì„ ì¤‘...")
        
        class Result:
            def __init__(self, final_output):
                self.final_output = final_output
        
        try:
            data = json.loads(input_data)
            user_feedback = data.get("user_feedback", "")
            
            # í”¼ë“œë°± ë¶„ì„ ë¡œì§
            understood_feedback = "í”¼ë“œë°±ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤."
            feedback_category = "general"
            required_changes = []
            revision_strategy = "ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ë¥¼ ìœ ì§€í•˜ê³  í”¼ë“œë°±ì— ë”°ë¼ ê°œì„ í•©ë‹ˆë‹¤."
            estimated_impact = 0.0 # 0-10 ì ìˆ˜

            # ê°„ë‹¨í•œ ë¶„ì„ ë¡œì§ (ì‹¤ì œ ë¶„ì„ì€ ë” ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŒ)
            if "ëª¨í˜¸í•œ í‘œí˜„" in user_feedback:
                understood_feedback = "í”¼ë“œë°±ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤. ëª¨í˜¸í•œ í‘œí˜„ì„ ì œê±°í•˜ê² ìŠµë‹ˆë‹¤."
                required_changes.append("ëª¨í˜¸í•œ í‘œí˜„ ì œê±°")
                revision_strategy = "ëª¨í˜¸í•œ í‘œí˜„ì„ ì œê±°í•˜ì—¬ ëª…í™•ì„±ì„ ë†’ì´ê² ìŠµë‹ˆë‹¤."
                estimated_impact = 0.8 # ë†’ì€ ì˜í–¥
            elif "ë„ˆë¬´ ì§§ì€ ì‘ë‹µ" in user_feedback:
                understood_feedback = "í”¼ë“œë°±ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤."
                required_changes.append("ë” êµ¬ì²´ì ì¸ ì‘ë‹µ ì œê³µ")
                revision_strategy = "ë” êµ¬ì²´ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ì—¬ ëª…í™•ì„±ì„ ë†’ì´ê² ìŠµë‹ˆë‹¤."
                estimated_impact = 0.6 # ë†’ì€ ì˜í–¥
            elif "ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­" in user_feedback:
                understood_feedback = "í”¼ë“œë°±ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­ì— ëŒ€í•œ ìš°ì„ ìˆœìœ„ë¥¼ ëª…í™•íˆ í•˜ê² ìŠµë‹ˆë‹¤."
                required_changes.append("ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­ì— ëŒ€í•œ ìš°ì„ ìˆœìœ„ ëª…í™•íˆ í•˜ê¸°")
                revision_strategy = "ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­ì— ëŒ€í•œ ìš°ì„ ìˆœìœ„ë¥¼ ëª…í™•íˆ í•˜ì—¬ ëª…í™•ì„±ì„ ë†’ì´ê² ìŠµë‹ˆë‹¤."
                estimated_impact = 0.7 # ë†’ì€ ì˜í–¥
            elif "ë„êµ¬ ì‚¬ìš©" in user_feedback:
                understood_feedback = "í”¼ë“œë°±ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤. ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ëª…í™•í•œ ì§€ì¹¨ì„ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤."
                required_changes.append("ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ëª…í™•í•œ ì§€ì¹¨ ì¶”ê°€")
                revision_strategy = "ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ëª…í™•í•œ ì§€ì¹¨ì„ ì¶”ê°€í•˜ì—¬ ì—ì´ì „í‹± ëŠ¥ë ¥ì„ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤."
                estimated_impact = 0.9 # ë†’ì€ ì˜í–¥
            elif "ê³„íš ìˆ˜ë¦½" in user_feedback:
                understood_feedback = "í”¼ë“œë°±ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤. ê³„íš ìˆ˜ë¦½ ë° ë°˜ì„±ì  ì‚¬ê³ ì— ëŒ€í•œ ì§€ì¹¨ì„ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤."
                required_changes.append("ê³„íš ìˆ˜ë¦½ ë° ë°˜ì„±ì  ì‚¬ê³ ì— ëŒ€í•œ ì§€ì¹¨ ì¶”ê°€")
                revision_strategy = "ê³„íš ìˆ˜ë¦½ ë° ë°˜ì„±ì  ì‚¬ê³ ì— ëŒ€í•œ ì§€ì¹¨ì„ ì¶”ê°€í•˜ì—¬ ì—ì´ì „í‹± ëŠ¥ë ¥ì„ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤."
                estimated_impact = 0.8 # ë†’ì€ ì˜í–¥
            else:
                understood_feedback = "í”¼ë“œë°±ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤. í”¼ë“œë°±ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤."
                required_changes = []
                revision_strategy = "í”¼ë“œë°±ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤."
                estimated_impact = 0.5 # ì¤‘ê°„ ì˜í–¥

            result = FeedbackAnalysis(
                understood_feedback=understood_feedback,
                feedback_category=feedback_category,
                required_changes=required_changes,
                revision_strategy=revision_strategy,
                estimated_impact=estimated_impact
            )
            
            if progress_callback:
                progress_callback(f"âœ… í”¼ë“œë°± ë¶„ì„ ì™„ë£Œ: ì´í•´ë„ {estimated_impact:.1f}/10")
            
            return Result(result)
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"âŒ í”¼ë“œë°± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return Result(FeedbackAnalysis(
                understood_feedback="í”¼ë“œë°± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                feedback_category="error",
                required_changes=[],
                revision_strategy="í”¼ë“œë°± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                estimated_impact=0
            ))

    @staticmethod
    async def _revise_prompt_with_feedback(agent: Agent, input_data: str, progress_callback=None):
        if progress_callback:
            progress_callback("âœï¸ í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì¤‘...")
        
        class Result:
            def __init__(self, final_output):
                self.final_output = final_output
        
        try:
            data = json.loads(input_data)
            original_optimized_prompt = data.get("original_optimized_prompt", "")
            user_feedback = data.get("user_feedback", "")
            
            # í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ë¡œì§
            revised_prompt = original_optimized_prompt
            changes_made = []
            feedback_addressed = []
            improvement_explanation = "í”¼ë“œë°±ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤."

            # ëª¨í˜¸í•œ í‘œí˜„ ì œê±°
            if "ëª¨í˜¸í•œ í‘œí˜„" in user_feedback:
                revised_prompt = revised_prompt.replace('maybe', 'specifically').replace('perhaps', 'exactly')
                changes_made.append("ëª¨í˜¸í•œ í‘œí˜„ ì œê±°")
                feedback_addressed.append("ëª¨í˜¸í•œ í‘œí˜„ ì œê±°")
                improvement_explanation += " ëª¨í˜¸í•œ í‘œí˜„ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤."

            # ë„ˆë¬´ ì§§ì€ ì‘ë‹µ ê°œì„ 
            if "ë„ˆë¬´ ì§§ì€ ì‘ë‹µ" in user_feedback:
                revised_prompt += "\n\nPlease provide detailed, comprehensive responses with clear explanations."
                changes_made.append("ë” êµ¬ì²´ì ì¸ ì‘ë‹µ ì œê³µ")
                feedback_addressed.append("ë„ˆë¬´ ì§§ì€ ì‘ë‹µ ê°œì„ ")
                improvement_explanation += " ë” êµ¬ì²´ì ì¸ ì‘ë‹µì„ ì œê³µí–ˆìŠµë‹ˆë‹¤."

            # ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­ ê°•ì¡°
            if "ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­" in user_feedback:
                revised_prompt += "\n\nPlease prioritize important instructions and ensure they are clear."
                changes_made.append("ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­ì— ëŒ€í•œ ìš°ì„ ìˆœìœ„ ëª…í™•íˆ í•˜ê¸°")
                feedback_addressed.append("ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­ ê°•ì¡°")
                improvement_explanation += " ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­ì— ëŒ€í•œ ìš°ì„ ìˆœìœ„ë¥¼ ëª…í™•íˆ í–ˆìŠµë‹ˆë‹¤."

            # ë„êµ¬ ì‚¬ìš© ì§€ì¹¨ ì¶”ê°€
            if "ë„êµ¬ ì‚¬ìš©" in user_feedback:
                revised_prompt += "\n\nIf you are not sure about information needed for the task, use available tools to gather relevant information - do NOT guess or make up an answer."
                changes_made.append("ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ëª…í™•í•œ ì§€ì¹¨ ì¶”ê°€")
                feedback_addressed.append("ë„êµ¬ ì‚¬ìš© ì§€ì¹¨ ì¶”ê°€")
                improvement_explanation += " ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ëª…í™•í•œ ì§€ì¹¨ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤."

            # ê³„íš ìˆ˜ë¦½ ì§€ì¹¨ ì¶”ê°€
            if "ê³„íš ìˆ˜ë¦½" in user_feedback:
                revised_prompt += "\n\nPlan extensively before taking action, and reflect on the outcomes of your actions."
                changes_made.append("ê³„íš ìˆ˜ë¦½ ì§€ì¹¨ ì¶”ê°€")
                feedback_addressed.append("ê³„íš ìˆ˜ë¦½ ì§€ì¹¨ ì¶”ê°€")
                improvement_explanation += " ê³„íš ìˆ˜ë¦½ ë° ë°˜ì„±ì  ì‚¬ê³ ì— ëŒ€í•œ ì§€ì¹¨ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤."

            # ì¶œë ¥ í˜•ì‹ ëª…ì‹œ
            if 'format' not in revised_prompt.lower():
                revised_prompt += "\n\nProvide your response in a clear, structured format."
                changes_made.append("ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ ì¶”ê°€")
                feedback_addressed.append("ì¶œë ¥ í˜•ì‹ ëª…ì‹œ")
                improvement_explanation += " ì¶œë ¥ í˜•ì‹ì„ ëª…ì‹œí–ˆìŠµë‹ˆë‹¤."

            result = RevisedPrompt(
                original_optimized_prompt=original_optimized_prompt,
                user_feedback=user_feedback,
                revised_prompt=revised_prompt,
                changes_made=changes_made,
                feedback_addressed=feedback_addressed,
                improvement_explanation=improvement_explanation
            )
            
            if progress_callback:
                progress_callback(f"âœ… í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì™„ë£Œ: {len(changes_made)}ê°œ ê°œì„ ì‚¬í•­ ì ìš©")
            
            return Result(result)
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"âŒ í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return Result(RevisedPrompt(
                original_optimized_prompt=input_data,
                user_feedback=input_data,
                revised_prompt=input_data,
                changes_made=[],
                feedback_addressed=[],
                improvement_explanation="í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
            ))

# Agent ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
clarity_checker = Agent(
    name="clarity_checker",
    model="gpt-4.1",
    output_type=Issues,
    instructions="Analyze prompt clarity based on GPT-4.1 guidelines"
)

specificity_checker = Agent(
    name="specificity_checker", 
    model="gpt-4.1",
    output_type=Issues,
    instructions="Analyze prompt specificity and concrete instructions"
)

instruction_following_checker = Agent(
    name="instruction_following_checker",
    model="gpt-4.1", 
    output_type=Issues,
    instructions="Check for contradictory or unclear instructions"
)

agentic_capability_checker = Agent(
    name="agentic_capability_checker",
    model="gpt-4.1",
    output_type=Issues,
    instructions="Analyze agentic workflow capabilities based on GPT-4.1 guide"
)

prompt_optimizer = Agent(
    name="prompt_optimizer",
    model="gpt-4.1",
    output_type=OptimizedPrompt,
    instructions="Optimize prompts based on GPT-4.1 best practices"
)

few_shot_optimizer = Agent(
    name="few_shot_optimizer",
    model="gpt-4.1",
    output_type=dict,
    instructions="Optimize few-shot examples for better performance"
)

feedback_analyzer = Agent(
    name="feedback_analyzer",
    model="gpt-4.1",
    output_type=FeedbackAnalysis,
    instructions="Analyze user feedback to understand their concerns and suggest improvements"
)

prompt_reviser = Agent(
    name="prompt_reviser",
    model="gpt-4.1",
    output_type=RevisedPrompt,
    instructions="Revise the prompt based on user feedback to improve clarity and adherence"
)

# ë©”ì¸ ìµœì í™” í•¨ìˆ˜
async def optimize_prompt_comprehensive(
    prompt: str,
    few_shot_messages: List[ChatMessage] = None,
    progress_callback=None
) -> Dict[str, Any]:
    """GPT-4.1 ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ì¢…í•©ì  í”„ë¡¬í”„íŠ¸ ìµœì í™”"""
    
    if progress_callback:
        progress_callback("ğŸš€ ì¢…í•©ì  í”„ë¡¬í”„íŠ¸ ë¶„ì„ ì‹œì‘...")
    
    # 1ë‹¨ê³„: ë³‘ë ¬ ë¶„ì„
    analysis_tasks = [
        Runner.run(clarity_checker, prompt, progress_callback),
        Runner.run(specificity_checker, prompt, progress_callback),
        Runner.run(instruction_following_checker, prompt, progress_callback),
        Runner.run(agentic_capability_checker, prompt, progress_callback),
    ]
    
    analysis_results = await asyncio.gather(*analysis_tasks)
    
    # 2ë‹¨ê³„: ê²°ê³¼ ì§‘ê³„
    all_issues = [result.final_output.model_dump() for result in analysis_results]
    total_issues = sum(len(issues['issues']) for issues in all_issues)
    
    if progress_callback:
        progress_callback(f"ğŸ“Š ë¶„ì„ ì™„ë£Œ: ì´ {total_issues}ê°œ ë¬¸ì œ ë°œê²¬")
    
    # 3ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ìµœì í™”
    optimization_input = {
        "original_prompt": prompt,
        "all_issues": all_issues
    }
    
    optimization_result = await Runner.run(
        prompt_optimizer, 
        json.dumps(optimization_input),
        progress_callback
    )
    
    # 4ë‹¨ê³„: Few-shot ìµœì í™” (ìˆëŠ” ê²½ìš°)
    final_messages = few_shot_messages or []
    if few_shot_messages:
        few_shot_input = {
            "messages": [msg.model_dump() for msg in few_shot_messages],
            "optimized_prompt": optimization_result.final_output.optimized_prompt
        }
        few_shot_result = await Runner.run(
            few_shot_optimizer,
            json.dumps(few_shot_input),
            progress_callback
        )
        final_messages = few_shot_result.final_output.get("messages", [])
    
    return {
        "original_prompt": prompt,
        "optimized_prompt": optimization_result.final_output.optimized_prompt,
        "analysis_results": all_issues,
        "optimization_details": optimization_result.final_output.model_dump(),
        "optimized_messages": final_messages,
        "total_issues_found": total_issues,
        "estimated_improvement": optimization_result.final_output.estimated_improvement
    }

async def revise_prompt_with_feedback(
    optimized_prompt: str,
    user_feedback: str,
    progress_callback=None
) -> Dict[str, Any]:
    """í”¼ë“œë°±ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€ ê°œì„ """
    
    if progress_callback:
        progress_callback("ğŸ” í”¼ë“œë°± ë¶„ì„ ì‹œì‘...")
    
    # 1ë‹¨ê³„: í”¼ë“œë°± ë¶„ì„
    feedback_input = {
        "user_feedback": user_feedback
    }
    
    feedback_analysis_result = await Runner.run(
        feedback_analyzer,
        json.dumps(feedback_input),
        progress_callback
    )
    
    if progress_callback:
        progress_callback("âœï¸ í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì‹œì‘...")
    
    # 2ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
    revision_input = {
        "original_optimized_prompt": optimized_prompt,
        "user_feedback": user_feedback
    }
    
    revision_result = await Runner.run(
        prompt_reviser,
        json.dumps(revision_input),
        progress_callback
    )
    
    return {
        "original_optimized_prompt": optimized_prompt,
        "user_feedback": user_feedback,
        "feedback_analysis": feedback_analysis_result.final_output.model_dump(),
        "revision_details": revision_result.final_output.model_dump(),
        "revised_prompt": revision_result.final_output.revised_prompt,
        "changes_made": revision_result.final_output.changes_made,
        "feedback_addressed": revision_result.final_output.feedback_addressed
    } 