import streamlit as st
import asyncio
import json
from typing import List, Dict, Any
import time
from prompt_optimizer import (
    optimize_prompt_comprehensive, 
    revise_prompt_with_feedback,
    run_general_agent,
    ChatMessage, 
    Role
)
from language_config import LANGUAGES, TEXTS

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="GPT-4.1 Prompt Optimizer",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì–¸ì–´ ì„¤ì • ì´ˆê¸°í™”
if 'language' not in st.session_state:
    st.session_state.language = 'ko'

def get_text(key: str) -> str:
    """í˜„ì¬ ì„ íƒëœ ì–¸ì–´ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ë°˜í™˜"""
    return TEXTS[st.session_state.language].get(key, key)

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title(get_text("sidebar_title"))
st.sidebar.markdown("---")

# ì–¸ì–´ ì„ íƒ
st.sidebar.subheader(get_text("language_select"))
selected_language = st.sidebar.selectbox(
    "Select Language / ì–¸ì–´ ì„ íƒ",
    options=list(LANGUAGES.keys()),
    index=0 if st.session_state.language == 'ko' else 1,
    key="language_selector"
)

# ì–¸ì–´ ë³€ê²½ ì‹œ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
if LANGUAGES[selected_language] != st.session_state.language:
    st.session_state.language = LANGUAGES[selected_language]
    st.rerun()

st.sidebar.markdown("---")

# OpenAI API ì„¤ì •
st.sidebar.subheader(get_text("openai_settings"))

# API í‚¤ ì…ë ¥
api_key = st.sidebar.text_input(
    get_text("api_key_input"),
    type="password",
    help=get_text("api_key_help")
)

# GPT ëª¨ë¸ ì„ íƒ
gpt_model = st.sidebar.selectbox(
    get_text("model_select"),
    [
        "gpt-4o-mini",
        "gpt-4o", 
        "gpt-4.1",
        "gpt-4-turbo",
        "gpt-4",
        "gpt-3.5-turbo"
    ],
    index=0,
    help=get_text("model_help")
)

# API í‚¤ ìƒíƒœ í‘œì‹œ
if api_key:
    st.sidebar.success(get_text("api_key_set"))
else:
    st.sidebar.warning(get_text("api_key_warning"))

st.sidebar.markdown("---")

# ì—°ë½ì²˜ ì •ë³´
st.sidebar.subheader(get_text("contact_info"))
st.sidebar.markdown(get_text("contact_text"))

st.sidebar.markdown("---")

# OpenAI Cookbook ì°¸ê³  ëª…ì‹œ
st.sidebar.subheader(get_text("reference_materials"))
st.sidebar.markdown(get_text("reference_text"))

st.sidebar.markdown("---")

# ë²„ì „ ì •ë³´
st.sidebar.caption(get_text("version"))

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'optimization_results' not in st.session_state:
    st.session_state.optimization_results = None
if 'progress_messages' not in st.session_state:
    st.session_state.progress_messages = []
if 'few_shot_messages' not in st.session_state:
    st.session_state.few_shot_messages = []
if 'revision_results' not in st.session_state:
    st.session_state.revision_results = None
if 'feedback_progress' not in st.session_state:
    st.session_state.feedback_progress = []
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

def add_progress_message(message: str):
    """ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ì¶”ê°€"""
    st.session_state.progress_messages.append({
        'timestamp': time.time(),
        'message': message
    })

def highlight_differences(original: str, modified: str):
    """ì›ë³¸ê³¼ ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ì˜ ì°¨ì´ì ì„ í•˜ì´ë¼ì´íŠ¸"""
    import difflib
    import html
    import re
    
    # HTML ì´ìŠ¤ì¼€ì´í•‘
    original_escaped = html.escape(original)
    modified_escaped = html.escape(modified)
    
    # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í•  (ë” ì•ˆì „í•œ ë°©ì‹)
    original_words = re.findall(r'\S+|\s+', original)
    modified_words = re.findall(r'\S+|\s+', modified)
    
    # ì°¨ì´ì  ê³„ì‚°
    try:
        diff = list(difflib.unified_diff(original_words, modified_words, lineterm=''))
        
        # ì¶”ê°€ëœ/ì œê±°ëœ ë‹¨ì–´ë“¤ ì°¾ê¸° (ê³µë°± ì œì™¸)
        added_words = [line[1:].strip() for line in diff if line.startswith('+') and not line.startswith('+++') and line[1:].strip()]
        removed_words = [line[1:].strip() for line in diff if line.startswith('-') and not line.startswith('---') and line[1:].strip()]
        
        highlighted_original = original_escaped
        highlighted_modified = modified_escaped
        
        # ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ì—ì„œ ìƒˆë¡œìš´ ë‚´ìš© í•˜ì´ë¼ì´íŠ¸ (ì–´ë‘ìš´ í…Œë§ˆìš©)
        for word in added_words[:5]:  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ
            if word and len(word) > 2:  # ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë§Œ
                word_escaped = html.escape(word)
                highlighted_modified = highlighted_modified.replace(
                    word_escaped, 
                    f"<mark style='background-color: #2d5a27; color: #81c784; padding: 3px 5px; border-radius: 4px; font-weight: bold;'>{word_escaped}</mark>"
                )
        
        # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì œê±°ëœ ë‚´ìš© í•˜ì´ë¼ì´íŠ¸ (ì–´ë‘ìš´ í…Œë§ˆìš©)
        for word in removed_words[:5]:  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ
            if word and len(word) > 2:  # ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë§Œ
                word_escaped = html.escape(word)
                highlighted_original = highlighted_original.replace(
                    word_escaped, 
                    f"<mark style='background-color: #5c1e1e; color: #ef5350; padding: 3px 5px; border-radius: 4px; font-weight: bold;'>{word_escaped}</mark>"
                )
                
        return highlighted_original, highlighted_modified
        
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ë°˜í™˜
        return original_escaped, modified_escaped

def add_feedback_progress(message: str):
    """í”¼ë“œë°± ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ì¶”ê°€"""
    st.session_state.feedback_progress.append({
        'timestamp': time.time(),
        'message': message
    })

async def run_optimization(prompt: str, prompt_type: str = None, num_candidates: int = 3, api_key: str = None, model: str = "gpt-4o"):
    """ë¹„ë™ê¸° ìµœì í™” ì‹¤í–‰"""
    st.session_state.progress_messages = []
    
    def progress_callback(message: str):
        add_progress_message(message)
        # Streamlit ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ rerunì€ ë³„ë„ ì²˜ë¦¬
    
    try:
        results = await optimize_prompt_comprehensive(
            prompt=prompt,
            prompt_type=prompt_type,
            num_candidates=num_candidates,
            progress_callback=progress_callback,
            api_key=api_key,
            model=model
        )
        st.session_state.optimization_results = results
        add_progress_message("âœ… ìµœì í™” ì™„ë£Œ!")
        return results
    except Exception as e:
        add_progress_message(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

async def run_feedback_revision(optimized_prompt: str, user_feedback: str, api_key: str = None, model: str = "gpt-4o"):
    """í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê°œì„  ì‹¤í–‰"""
    st.session_state.feedback_progress = []
    
    def feedback_progress_callback(message: str):
        add_feedback_progress(message)
    
    try:
        results = await revise_prompt_with_feedback(
            optimized_prompt=optimized_prompt,
            user_feedback=user_feedback,
            progress_callback=feedback_progress_callback,
            api_key=api_key,
            model=model
        )
        st.session_state.revision_results = results
        add_feedback_progress("âœ… í”¼ë“œë°± ê¸°ë°˜ ê°œì„  ì™„ë£Œ!")
        return results
    except Exception as e:
        add_feedback_progress(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def display_severity_badge(severity: str):
    """ì‹¬ê°ë„ ë°°ì§€ í‘œì‹œ"""
    colors = {
        "low": "ğŸŸ¢",
        "medium": "ğŸŸ¡", 
        "high": "ğŸ”´"
    }
    return f"{colors.get(severity, 'âšª')} {severity.upper()}"

def display_category_badge(category: str):
    """ì¹´í…Œê³ ë¦¬ ë°°ì§€ í‘œì‹œ"""
    emoji_map = {
        "clarity": "ğŸ“‹",
        "specificity": "ğŸ¯",
        "instruction_following": "ğŸ“",
        "agentic_capabilities": "ğŸ¤–"
    }
    return f"{emoji_map.get(category, 'ğŸ“')} {category.replace('_', ' ').title()}"

# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
st.title(get_text("main_title"))
st.markdown(get_text("main_description"))

# OpenAI Cookbook ì°¸ê³  ëª…ì‹œ
st.info(get_text("reference_info"))

# íƒ­ ìƒì„±
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    get_text("tab_input"), 
    get_text("tab_progress"), 
    get_text("tab_analysis"), 
    get_text("tab_optimization"),
    get_text("tab_feedback")
])

# íƒ­ 1: í”„ë¡¬í”„íŠ¸ ì…ë ¥
with tab1:
    st.header(get_text("prompt_input_header"))
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader(get_text("main_prompt"))
        user_prompt = st.text_area(
            get_text("main_prompt"),
            height=300,
            placeholder=get_text("prompt_placeholder"),
            help=get_text("prompt_help")
        )
        
        # ìµœì í™” ì‹¤í–‰ ë²„íŠ¼ì„ ì™¼ìª½ ì—´ í•˜ë‹¨ì— ë°°ì¹˜
        st.markdown("---")
        if st.button(get_text("start_optimization"), type="primary", use_container_width=True, key="start_optimization_btn"):
            if not api_key:
                st.error(get_text("api_key_required"))
            elif user_prompt.strip():
                # ë¹„ë™ê¸° ìµœì í™” ì‹¤í–‰
                with st.spinner(get_text("optimizing_prompt")):
                    results = asyncio.run(run_optimization(
                        prompt=user_prompt,
                        prompt_type=selected_type,
                        num_candidates=num_candidates,
                        api_key=api_key,
                        model=gpt_model
                    ))
                
                if results:
                    st.success(get_text("optimization_complete"))
                    st.balloons()
                else:
                    st.error(get_text("optimization_error"))
            else:
                st.error(get_text("prompt_required"))
    
    with col2:
        st.subheader(get_text("prompt_type"))
        
        # í”„ë¡¬í”„íŠ¸ ìœ í˜• ì„ íƒ (ìë™ ê°ì§€ ì˜µì…˜ í¬í•¨)
        prompt_type_options = [
            "ìë™ ê°ì§€",
            "ì°½ì˜ì  ê¸€ì“°ê¸° (creative_writing)",
            "ì½”ë“œ ìƒì„± (code_generation)",
            "ì§ˆë¬¸ ë‹µë³€ (qa)",
            "ë¶„ì„ (analysis)",
            "ì§€ì‹œì‚¬í•­ ìˆ˜í–‰ (instruction_following)"
        ]
        
        selected_prompt_type = st.selectbox(
            "í”„ë¡¬í”„íŠ¸ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”",
            prompt_type_options,
            help="í”„ë¡¬í”„íŠ¸ ìœ í˜•ì„ ì„ íƒí•˜ë©´ í•´ë‹¹ ìœ í˜•ì— ìµœì í™”ëœ ì „ëµì´ ì ìš©ë©ë‹ˆë‹¤. 'ìë™ ê°ì§€'ë¥¼ ì„ íƒí•˜ë©´ AIê°€ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìœ í˜•ì„ íŒë‹¨í•©ë‹ˆë‹¤."
        )
        
        # ì„ íƒëœ ìœ í˜•ì„ ì˜ì–´ í‚¤ë¡œ ë³€í™˜
        prompt_type_map = {
            "ìë™ ê°ì§€": None,
            "ì°½ì˜ì  ê¸€ì“°ê¸° (creative_writing)": "creative_writing",
            "ì½”ë“œ ìƒì„± (code_generation)": "code_generation",
            "ì§ˆë¬¸ ë‹µë³€ (qa)": "qa",
            "ë¶„ì„ (analysis)": "analysis",
            "ì§€ì‹œì‚¬í•­ ìˆ˜í–‰ (instruction_following)": "instruction_following"
        }
        
        selected_type = prompt_type_map.get(selected_prompt_type)
        
        st.markdown("---")
        
        # í”„ë¡¬í”„íŠ¸ í›„ë³´ ìƒì„± ê°œìˆ˜ ì„¤ì •
        st.subheader("ğŸ”„ í”„ë¡¬í”„íŠ¸ ìµœì í™” ì „ëµ")
        
        num_candidates = st.slider(
            "ìƒì„±í•  í”„ë¡¬í”„íŠ¸ ë³€í˜• ê°œìˆ˜",
            min_value=2,
            max_value=5,
            value=3,
            help="ë” ë§ì€ ë³€í˜•ì„ ìƒì„±í•˜ë©´ ë” ë‹¤ì–‘í•œ ìµœì í™” ì˜µì…˜ì„ íƒìƒ‰í•  ìˆ˜ ìˆì§€ë§Œ, ì²˜ë¦¬ ì‹œê°„ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤."
        )
        
        # ê³ ê¸‰ ìµœì í™” ì „ëµ í‘œì‹œ
        with st.expander("ğŸ“Š ìµœì í™” ì „ëµ ìƒì„¸"):
            st.info("""
            **í”„ë¡¬í”„íŠ¸ ìµœì í™” í”„ë¡œì„¸ìŠ¤:**
            
            1. **í”„ë¡¬í”„íŠ¸ ìœ í˜• ê°ì§€**: AIê°€ í”„ë¡¬í”„íŠ¸ì˜ ëª©ì ê³¼ íŠ¹ì„±ì„ ë¶„ì„
            2. **í›„ë³´ ìƒì„±**: ë‹¤ì–‘í•œ ë³€í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
            3. **í‰ê°€ ë° ì±„ì **: 
               - ëª¨ìˆœ ê²€ì‚¬ (Contradiction Check)
               - í˜•ì‹ ê²€ì¦ (Format Validation)
               - ì•ˆì „ì„± ê²€ì‚¬ (Safety & Bias Check)
               - ê´€ë ¨ì„± í‰ê°€ (Relevance Evaluation)
            4. **ìˆœìœ„ ë§¤ê¸°ê¸°**: ì¢…í•© ì ìˆ˜ ê¸°ë°˜ ìµœì  í”„ë¡¬í”„íŠ¸ ì„ íƒ
            5. **ìµœì¢… ìµœì í™”**: ì„ íƒëœ í”„ë¡¬í”„íŠ¸ ì¶”ê°€ ê°œì„ 
            """)
        
        # ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ ì œê³µ
        st.markdown("---")
        st.subheader("ğŸ’¡ ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸")
        
        example_prompts = {
            "ì°½ì˜ì  ê¸€ì“°ê¸°": "í•œêµ­ì˜ ì „í†µ ìŒì‹ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ ì´ì•¼ê¸°ë¥¼ ì¨ì£¼ì„¸ìš”. ì—­ì‚¬ì  ë°°ê²½ê³¼ í˜„ëŒ€ì  ì˜ë¯¸ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.",
            "ì½”ë“œ ìƒì„±": "Pythonìœ¼ë¡œ ê°„ë‹¨í•œ í•  ì¼ ëª©ë¡ ì•±ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ì¶”ê°€, ì‚­ì œ, ì™„ë£Œ í‘œì‹œ ê¸°ëŠ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            "ì§ˆë¬¸ ë‹µë³€": "ì¸ê³µì§€ëŠ¥ì´ ì¸ê°„ì˜ ì°½ì˜ì„±ì„ ëŒ€ì²´í•  ìˆ˜ ìˆì„ê¹Œìš”? ì¥ë‹¨ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
            "ë¶„ì„": "ìµœê·¼ 5ë…„ê°„ ì „ê¸°ì°¨ ì‹œì¥ì˜ ì„±ì¥ ì¶”ì„¸ë¥¼ ë¶„ì„í•˜ê³  í–¥í›„ ì „ë§ì„ ì œì‹œí•´ì£¼ì„¸ìš”.",
            "ì§€ì‹œì‚¬í•­ ìˆ˜í–‰": "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ê³ , í•µì‹¬ í¬ì¸íŠ¸ 3ê°€ì§€ë¥¼ bullet pointë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”: [í…ìŠ¤íŠ¸]"
        }
        
        selected_example = st.selectbox(
            "ì˜ˆì‹œ ì„ íƒ",
            ["ì§ì ‘ ì…ë ¥"] + list(example_prompts.keys())
        )
        
        if selected_example != "ì§ì ‘ ì…ë ¥" and st.button("ì˜ˆì‹œ ì‚¬ìš©", key="use_example"):
            # ì˜ˆì‹œë¥¼ ë©”ì¸ í”„ë¡¬í”„íŠ¸ ì…ë ¥ë€ì— ì„¤ì •í•˜ëŠ” ë°©ë²•ì€ 
            # Streamlitì˜ ì œì•½ìœ¼ë¡œ ì¸í•´ ì„¸ì…˜ ìƒíƒœë¥¼ í†µí•´ ì²˜ë¦¬í•´ì•¼ í•¨
            st.info(f"ì„ íƒí•œ ì˜ˆì‹œ: {example_prompts[selected_example]}")
            st.markdown("ğŸ‘† ìœ„ ì˜ˆì‹œë¥¼ ë³µì‚¬í•˜ì—¬ ì™¼ìª½ í”„ë¡¬í”„íŠ¸ ì…ë ¥ë€ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")

# íƒ­ 2: ë¶„ì„ ì§„í–‰
with tab2:
    st.header("ğŸ” ë¶„ì„ ì§„í–‰ ìƒí™©")
    
    if st.session_state.progress_messages:
        st.subheader("ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©")
        
        # ì§„í–‰ ìƒí™© ì»¨í…Œì´ë„ˆ
        progress_container = st.container()
        
        with progress_container:
            for i, msg in enumerate(st.session_state.progress_messages):
                timestamp = time.strftime("%H:%M:%S", time.localtime(msg['timestamp']))
                st.write(f"`{timestamp}` {msg['message']}")
        
        # ì§„í–‰ë¥  ê³„ì‚° (ëŒ€ëµì )
        total_steps = 8  # ì˜ˆìƒ ì´ ë‹¨ê³„
        current_step = len(st.session_state.progress_messages)
        progress = min(current_step / total_steps, 1.0)
        
        st.progress(progress)
        st.caption(f"ì§„í–‰ë¥ : {progress * 100:.0f}%")
        
        # ìë™ ìƒˆë¡œê³ ì¹¨
        if progress < 1.0:
            time.sleep(1)
            st.rerun()
    else:
        st.info("ğŸ’¡ 'í”„ë¡¬í”„íŠ¸ ì…ë ¥' íƒ­ì—ì„œ ìµœì í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
        
        # ìƒ˜í”Œ ì§„í–‰ ìƒí™© í‘œì‹œ
        st.subheader("ì˜ˆìƒ ë¶„ì„ ë‹¨ê³„")
        sample_steps = [
            "ğŸš€ ì¢…í•©ì  í”„ë¡¬í”„íŠ¸ ë¶„ì„ ì‹œì‘...",
            "ğŸ” Agent 'clarity_checker' ì‹¤í–‰ ì¤‘...",
            "ğŸ“‹ ëª…í™•ì„± ë¶„ì„ ì¤‘...",
            "âœ… ëª…í™•ì„± ë¶„ì„ ì™„ë£Œ",
            "ğŸ¯ êµ¬ì²´ì„± ë¶„ì„ ì¤‘...",
            "âœ… êµ¬ì²´ì„± ë¶„ì„ ì™„ë£Œ",
            "ğŸ“ ì§€ì‹œì‚¬í•­ ì¤€ìˆ˜ ë¶„ì„ ì¤‘...",
            "âœ… ì§€ì‹œì‚¬í•­ ì¤€ìˆ˜ ë¶„ì„ ì™„ë£Œ",
            "ğŸ¤– ì—ì´ì „í‹± ëŠ¥ë ¥ ë¶„ì„ ì¤‘...",
            "âœ… ì—ì´ì „í‹± ëŠ¥ë ¥ ë¶„ì„ ì™„ë£Œ",
            "ğŸ“Š ë¶„ì„ ì™„ë£Œ: ì´ ë¬¸ì œ ì§‘ê³„",
            "âœï¸ í”„ë¡¬í”„íŠ¸ ìµœì í™” ì¤‘...",
            "âœ… í”„ë¡¬í”„íŠ¸ ìµœì í™” ì™„ë£Œ",
            "âœ… ìµœì í™” ì™„ë£Œ!"
        ]
        
        for step in sample_steps:
            st.text(step)

# íƒ­ 3: ë¶„ì„ ê²°ê³¼
with tab3:
    st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    if st.session_state.optimization_results:
        results = st.session_state.optimization_results
        
        # í”„ë¡¬í”„íŠ¸ ìœ í˜• ê°ì§€ ê²°ê³¼ í‘œì‹œ
        if results.get('type_detection'):
            st.info(f"""
            ğŸ” **ê°ì§€ëœ í”„ë¡¬í”„íŠ¸ ìœ í˜•**: {results['detected_type']} 
            (ì‹ ë¢°ë„: {results['type_detection']['confidence']:.2%})
            """)
        
        # ìš”ì•½ ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ìƒì„±ëœ í›„ë³´",
                len(results.get('prompt_candidates', [])),
                delta=None
            )
        
        with col2:
            st.metric(
                "ì˜ˆìƒ ê°œì„ ìœ¨",
                f"{results.get('estimated_improvement', 0):.0f}%",
                delta=f"+{results.get('estimated_improvement', 0):.0f}%"
            )
        
        with col3:
            # ìµœê³  ì ìˆ˜ í‘œì‹œ
            ranking_results = results.get('ranking_results', {})
            if ranking_results and ranking_results.get('ranked_prompts'):
                best_score = ranking_results['ranked_prompts'][0].get('final_score', 0)
                st.metric(
                    "ìµœê³  ì ìˆ˜",
                    f"{best_score:.2f}",
                    delta=None
                )
            else:
                st.metric("ìµœê³  ì ìˆ˜", "N/A", delta=None)
        
        with col4:
            changes_made = results.get('optimization_details', {}).get('changes_made', [])
            st.metric(
                "ì ìš©ëœ ê°œì„ ì‚¬í•­",
                len(changes_made),
                delta=f"+{len(changes_made)}"
            )
        
        st.markdown("---")
        
        # í”„ë¡¬í”„íŠ¸ í›„ë³´ ë° í‰ê°€ ê²°ê³¼
        st.subheader("ğŸ”„ í”„ë¡¬í”„íŠ¸ í›„ë³´ ìƒì„± ë° í‰ê°€")
        
        if results.get('prompt_candidates'):
            # ê° í›„ë³´ì˜ í‰ê°€ ì ìˆ˜ë¥¼ í‘œ í˜•íƒœë¡œ í‘œì‹œ
            candidate_evaluations = results.get('candidate_evaluations', [])
            
            for idx, (candidate, evaluation) in enumerate(zip(results['prompt_candidates'], candidate_evaluations)):
                with st.expander(f"í›„ë³´ {idx + 1} - ì¢…í•© ì ìˆ˜: {evaluation.get('contradiction_score', 0) * 0.3 + evaluation.get('format_score', 0) * 0.3 + evaluation.get('safety_score', 0) * 0.4:.2f}"):
                    # ì ìˆ˜ í‘œì‹œ
                    score_col1, score_col2, score_col3 = st.columns(3)
                    with score_col1:
                        st.metric("ëª¨ìˆœ ì ìˆ˜", f"{evaluation.get('contradiction_score', 0):.2f}")
                    with score_col2:
                        st.metric("í˜•ì‹ ì ìˆ˜", f"{evaluation.get('format_score', 0):.2f}")
                    with score_col3:
                        st.metric("ì•ˆì „ì„± ì ìˆ˜", f"{evaluation.get('safety_score', 0):.2f}")
                    
                    # í”„ë¡¬í”„íŠ¸ ë‚´ìš©
                    st.markdown("**í”„ë¡¬í”„íŠ¸ ë‚´ìš©:**")
                    st.code(candidate, language='text')
        
        st.markdown("---")
        
        # ìˆœìœ„ ê²°ê³¼
        st.subheader("ğŸ† ìµœì í™” ìˆœìœ„")
        
        ranking_results = results.get('ranking_results', {})
        if ranking_results and ranking_results.get('ranked_prompts'):
            for rank_info in ranking_results['ranked_prompts'][:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                rank = rank_info.get('rank', 0)
                score = rank_info.get('final_score', 0)
                prompt = rank_info.get('prompt', '')
                
                if rank == 1:
                    st.success(f"ğŸ¥‡ **1ìœ„** (ì ìˆ˜: {score:.2f})")
                elif rank == 2:
                    st.info(f"ğŸ¥ˆ **2ìœ„** (ì ìˆ˜: {score:.2f})")
                else:
                    st.warning(f"ğŸ¥‰ **3ìœ„** (ì ìˆ˜: {score:.2f})")
                
                st.code(prompt, language='text')
    else:
        st.info("ğŸ’¡ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”í•´ì£¼ì„¸ìš”.")

# íƒ­ 4: ìµœì í™” ê²°ê³¼
with tab4:
    st.header("âœ¨ ìµœì í™” ê²°ê³¼")
    
    if st.session_state.optimization_results:
        results = st.session_state.optimization_results
        optimization_details = results.get('optimization_details', {})
        
        # ë³€ê²½ì‚¬í•­ ë¹„êµ (ìœ„ë¡œ ì´ë™)
        st.subheader("ğŸ”„ ë³€ê²½ì‚¬í•­ ë¹„êµ")
        
        original_prompt = results.get('original_prompt', '')
        optimized_prompt = results.get('optimized_prompt', '')
        changes_made = optimization_details.get('changes_made', [])
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ“ ì›ë³¸ í”„ë¡¬í”„íŠ¸**")
            # Streamlit code ë¸”ë¡ ì‚¬ìš© (ì–´ë‘ìš´ ë°°ê²½ ìë™ ì ìš©)
            st.code(original_prompt, language='text', line_numbers=False)
        
        with col2:
            st.markdown("**âœ¨ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸**")
            # Streamlit code ë¸”ë¡ ì‚¬ìš© (ì–´ë‘ìš´ ë°°ê²½ ìë™ ì ìš©)
            st.code(optimized_prompt, language='text', line_numbers=False)
        
        # ì°¨ì´ì  í•˜ì´ë¼ì´íŠ¸ ì„¹ì…˜
        with st.expander("ğŸ” ì°¨ì´ì  í•˜ì´ë¼ì´íŠ¸ ë³´ê¸° (ì‹¤í—˜ì  ê¸°ëŠ¥)"):
            st.info("ğŸ’¡ ì´ ê¸°ëŠ¥ì€ ì‹¤í—˜ì ì´ë©°, ë³µì¡í•œ í…ìŠ¤íŠ¸ì—ì„œëŠ” ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            try:
                highlighted_original, highlighted_modified = highlight_differences(original_prompt, optimized_prompt)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ì›ë³¸ (ë¹¨ê°„ìƒ‰: ì œê±°ë¨)**")
                    if highlighted_original != original_prompt:
                        st.markdown(f"""
                        <div style="background-color: #2d3748; border: 1px solid #4a5568; border-radius: 8px; padding: 15px; height: 250px; overflow-y: auto; font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace; white-space: pre-wrap; color: #e2e8f0; line-height: 1.6; font-size: 13px;">
                        {highlighted_original}
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.code(original_prompt, language='text')
                
                with col2:
                    st.markdown("**ìµœì í™”ë¨ (ì´ˆë¡ìƒ‰: ì¶”ê°€ë¨)**")
                    if highlighted_modified != optimized_prompt:
                        st.markdown(f"""
                        <div style="background-color: #2d3748; border: 1px solid #4a5568; border-radius: 8px; padding: 15px; height: 250px; overflow-y: auto; font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace; white-space: pre-wrap; color: #e2e8f0; line-height: 1.6; font-size: 13px;">
                        {highlighted_modified}
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.code(optimized_prompt, language='text')
                        
            except Exception as e:
                st.error(f"ì°¨ì´ì  ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                
                # í´ë°±: ì¼ë°˜ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ í‘œì‹œ
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ì›ë³¸**")
                    st.code(original_prompt, language='text')
                with col2:
                    st.markdown("**ìµœì í™”ë¨**")
                    st.code(optimized_prompt, language='text')
        
        # í•˜ì´ë¼ì´íŠ¸ëœ ë³€ê²½ì‚¬í•­ ì„¤ëª…
        if changes_made:
            st.markdown("### ğŸ¯ ì£¼ìš” ë³€ê²½ì‚¬í•­")
            for i, change in enumerate(changes_made, 1):
                st.markdown(f"""
                <div style="background-color: #ffeb3b33; padding: 10px; border-left: 4px solid #ffeb3b; margin: 5px 0;">
                    <strong>{i}. âœ… {change}</strong>
                </div>
                """, unsafe_allow_html=True)
        
        # ê°œì„ ì‚¬í•­ ìš”ì•½ (ë¶„ì„ê²°ê³¼ì™€ í†µí•©)
        st.subheader("ğŸ“ˆ ì¢…í•© ë¶„ì„ ë° ê°œì„  ìš”ì•½")
        
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col1:
            st.info(f"**ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ **: {optimization_details.get('estimated_improvement', 0):.0f}%")
            
        with col2:
            st.success(f"**ì ìš©ëœ ê°œì„ ì‚¬í•­**: {len(changes_made)}ê°œ")
            
        with col3:
            # ë¶„ì„ ê²°ê³¼ì—ì„œ ë°œê²¬ëœ ì´ ë¬¸ì œ ê°œìˆ˜
            if hasattr(st.session_state, 'analysis_results') and st.session_state.analysis_results:
                analysis_results = st.session_state.analysis_results
                total_issues = sum(len(result.get('issues', [])) for result in analysis_results.get('analysis_details', []))
                st.warning(f"**í•´ê²°ëœ ë¬¸ì œ**: {total_issues}ê°œ")
            else:
                st.info("**ë¶„ì„ ì •ë³´**: ì—†ìŒ")
        
        # ê°œì„  ì„¤ëª…
        improvement_explanation = optimization_details.get('improvement_explanation', '')
        if improvement_explanation:
            st.subheader("ğŸ’¡ ê°œì„  ì„¤ëª…")
            st.write(improvement_explanation)
        
        st.markdown("---")
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸ì™€ ë²„íŠ¼ë“¤
        st.subheader("ğŸ“¥ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸")
        
        # í”„ë¡¬í”„íŠ¸ì™€ ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.text_area(
                "ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸",
                value=optimized_prompt,
                height=250,
                disabled=False,
                help="ì´ ì˜ì—­ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ì—¬ ë³µì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                label_visibility="collapsed"
            )
        
        with col2:
            st.markdown("**ğŸ“‹ ë‚´ë³´ë‚´ê¸°**")
            if st.button("ğŸ“‹ ë³µì‚¬", use_container_width=True, key="copy_final_prompt"):
                st.success("ğŸ“ ì™¼ìª½ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ì—¬ ë³µì‚¬í•˜ì„¸ìš”!")
            
            st.download_button(
                label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                data=optimized_prompt,
                file_name="optimized_prompt.txt",
                mime="text/plain",
                use_container_width=True
            )

        
        # Few-shot ì˜ˆì œ ìµœì í™” (ìˆëŠ” ê²½ìš°)
        optimized_messages = results.get('optimized_messages', [])
        if optimized_messages:
            st.subheader("ğŸ’¬ ìµœì í™”ëœ Few-shot ì˜ˆì œ")
            
            for i, msg in enumerate(optimized_messages):
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
                
                if role == 'user':
                    st.markdown(f"**ì‚¬ìš©ì {i//2 + 1}:**")
                    st.info(content)
                elif role == 'assistant':
                    st.markdown(f"**ì–´ì‹œìŠ¤í„´íŠ¸ {(i+1)//2}:**")
                    st.success(content)
        
        # ì¬ì‹œì‘ ë²„íŠ¼
        st.markdown("---")
        if st.button(get_text("new_optimization"), type="secondary", use_container_width=True, key="new_optimization_btn"):
            st.session_state.optimization_results = None
            st.session_state.progress_messages = []
            st.session_state.few_shot_messages = []
            st.rerun()
    
    else:
        st.info("ğŸ’¡ ìµœì í™” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”í•´ì£¼ì„¸ìš”.")

# íƒ­ 5: í”¼ë“œë°± & ë¦¬ë¹„ì „
with tab5:
    st.header("ğŸ”„ í”¼ë“œë°± & ë¦¬ë¹„ì „")
    
    if st.session_state.optimization_results:
        # í˜„ì¬ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
        st.subheader("ğŸ“ í˜„ì¬ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸")
        current_prompt = st.session_state.optimization_results.get('optimized_prompt', '')
        
        with st.expander("í˜„ì¬ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ë³´ê¸°", expanded=False):
            st.code(current_prompt, language='text')
        
        st.markdown("---")
        
        # í”¼ë“œë°± ì…ë ¥ ì„¹ì…˜
        st.subheader("ğŸ’¬ í”¼ë“œë°± ì œê³µ")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            user_feedback = st.text_area(
                "ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì‘ì„±í•´ì£¼ì„¸ìš”",
                height=150,
                placeholder="""ì˜ˆì‹œ í”¼ë“œë°±:
â€¢ í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ë³µì¡í•´ ë³´ì…ë‹ˆë‹¤. ë” ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
â€¢ ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ì§€ì¹¨ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.
â€¢ ì‘ë‹µì´ ë„ˆë¬´ ì§§ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë” ìƒì„¸í•œ ë‹µë³€ì„ ìš”êµ¬í•´ì£¼ì„¸ìš”.
â€¢ íŠ¹ì • í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ë„ë¡ ëª…ì‹œí•´ì£¼ì„¸ìš”.
â€¢ ê³„íš ìˆ˜ë¦½ ë‹¨ê³„ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.""",
                help="êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí• ìˆ˜ë¡ ë” ë‚˜ì€ ê°œì„  ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        
        with col2:
            st.subheader("í”¼ë“œë°± ì¹´í…Œê³ ë¦¬")
            feedback_category = st.selectbox(
                "í”¼ë“œë°± ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”",
                [
                    "ì¼ë°˜ì ì¸ ê°œì„ ì‚¬í•­",
                    "ëª…í™•ì„± ê°œì„ ",
                    "êµ¬ì²´ì„± ê°œì„ ", 
                    "ì§€ì‹œì‚¬í•­ ìˆ˜ì •",
                    "ì—ì´ì „í‹± ëŠ¥ë ¥ ê°œì„ ",
                    "í˜•ì‹ ê°œì„ ",
                    "ê¸°íƒ€"
                ]
            )
            
            feedback_priority = st.selectbox(
                "ìš°ì„ ìˆœìœ„",
                ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"]
            )
            
            # í”¼ë“œë°± ì˜ˆì‹œ ë²„íŠ¼ë“¤
            st.subheader(get_text("quick_feedback"))
            if st.button(get_text("feedback_complex"), use_container_width=True, key="quick_complex"):
                st.session_state.quick_feedback = get_text("quick_feedback_complex")
            
            if st.button(get_text("feedback_tools"), use_container_width=True, key="quick_tools"):
                st.session_state.quick_feedback = get_text("quick_feedback_tools")
            
            if st.button(get_text("feedback_length"), use_container_width=True, key="quick_length"):
                st.session_state.quick_feedback = get_text("quick_feedback_length")
            
            if st.button(get_text("feedback_planning"), use_container_width=True, key="quick_planning"):
                st.session_state.quick_feedback = get_text("quick_feedback_planning")
        
        # ë¹ ë¥¸ í”¼ë“œë°±ì´ ì„ íƒëœ ê²½ìš° ìë™ ì…ë ¥
        if 'quick_feedback' in st.session_state and st.session_state.quick_feedback:
            user_feedback = st.text_area(
                "ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì‘ì„±í•´ì£¼ì„¸ìš”",
                value=st.session_state.quick_feedback,
                height=150,
                key="feedback_with_quick"
            )
            st.session_state.quick_feedback = None  # ì´ˆê¸°í™”
        
        # í”¼ë“œë°± ê¸°ë°˜ ê°œì„  ì‹¤í–‰
        if st.button(get_text("start_feedback_improvement"), type="primary", use_container_width=True, key="start_feedback_btn"):
            if not api_key:
                st.error(get_text("api_key_required"))
            elif user_feedback.strip():
                with st.spinner("Analyzing feedback and improving prompt..." if st.session_state.language == 'en' else "í”¼ë“œë°±ì„ ë¶„ì„í•˜ê³  í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„  ì¤‘..."):
                    
                    # ë²”ìš© ìš”ì²­ í‚¤ì›Œë“œ ê°ì§€
                    general_keywords = ["í•œê¸€", "ì˜ì–´", "korean", "english", "translate", "ë²ˆì—­", "ë³€ê²½", "formal", "casual", "shorter", "longer", "ì •ì¤‘", "ì¹œê·¼", "ì§§ê²Œ", "ê¸¸ê²Œ", "ê°„ë‹¨", "ìì„¸íˆ"]
                    is_general_request = any(keyword in user_feedback.lower() for keyword in general_keywords)
                    
                    if is_general_request:
                        # ë²”ìš© Agent ì‚¬ìš©
                        general_results = asyncio.run(run_general_agent(
                            original_prompt=current_prompt,
                            user_feedback=user_feedback,
                            api_key=api_key,
                            model=gpt_model
                        ))
                        
                        if general_results:
                            # ë²”ìš© ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                            st.session_state.revision_results = {
                                "original_optimized_prompt": general_results["original_prompt"],
                                "user_feedback": general_results["user_feedback"],
                                "revised_prompt": general_results["modified_prompt"],
                                "changes_made": general_results["changes_made"],
                                "explanation": general_results["explanation"],
                                "feedback_addressed": [general_results["feedback_addressed"]],
                                "revision_details": {
                                    "changes_made": general_results["changes_made"],
                                    "feedback_addressed": [general_results["feedback_addressed"]]
                                }
                            }
                            st.success(get_text("feedback_complete"))
                            st.balloons()
                        else:
                            st.error(get_text("feedback_error"))
                    else:
                        # ê¸°ì¡´ ë¶„ì„ ê¸°ë°˜ ì‹œìŠ¤í…œ ì‚¬ìš©
                        results = asyncio.run(run_feedback_revision(
                            optimized_prompt=current_prompt,
                            user_feedback=user_feedback,
                            api_key=api_key,
                            model=gpt_model
                        ))
                        
                        if results:
                            st.success(get_text("feedback_complete"))
                            st.balloons()
                        else:
                            st.error(get_text("feedback_error"))
            else:
                st.error(get_text("feedback_required"))
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if st.session_state.feedback_progress:
            st.subheader("ğŸ” ê°œì„  ì§„í–‰ ìƒí™©")
            
            with st.container():
                for msg in st.session_state.feedback_progress:
                    timestamp = time.strftime("%H:%M:%S", time.localtime(msg['timestamp']))
                    st.write(f"`{timestamp}` {msg['message']}")
        
        # ë¦¬ë¹„ì „ ê²°ê³¼ í‘œì‹œ
        if st.session_state.revision_results:
            st.markdown("---")
            st.subheader("ğŸ“Š í”¼ë“œë°± ê¸°ë°˜ ê°œì„  ê²°ê³¼")
            
            # ê°œì„  ìš”ì•½
            col1, col2, col3 = st.columns(3)
            
            revision_details = st.session_state.revision_results.get('revision_details', {})
            changes_made = revision_details.get('changes_made', [])
            feedback_addressed = revision_details.get('feedback_addressed', [])
            
            with col1:
                st.metric("ì ìš©ëœ ë³€ê²½ì‚¬í•­", len(changes_made))
            
            with col2:
                st.metric("ì²˜ë¦¬ëœ í”¼ë“œë°±", len(feedback_addressed))
            
            with col3:
                # ê°œì„ ë„ ê³„ì‚° (ë³€ê²½ì‚¬í•­ ìˆ˜ ê¸°ë°˜)
                improvement_score = min(len(changes_made) * 20, 100)
                st.metric("ê°œì„  ì ìˆ˜", f"{improvement_score}%")
            
            # ì ìš©ëœ ë³€ê²½ì‚¬í•­
            if changes_made:
                st.subheader("ğŸ”§ ì ìš©ëœ ë³€ê²½ì‚¬í•­")
                for i, change in enumerate(changes_made, 1):
                    st.write(f"{i}. âœ… {change}")
            
            # ì²˜ë¦¬ëœ í”¼ë“œë°±
            if feedback_addressed:
                st.subheader("ğŸ’¬ ì²˜ë¦¬ëœ í”¼ë“œë°±")
                for i, feedback in enumerate(feedback_addressed, 1):
                    st.write(f"{i}. ğŸ“ {feedback}")
            
            # ê°œì„  ì„¤ëª…
            improvement_explanation = revision_details.get('improvement_explanation', '')
            if improvement_explanation:
                st.subheader("ğŸ’¡ ê°œì„  ì„¤ëª…")
                st.info(improvement_explanation)
            
            # ìµœì¢… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
            st.subheader("ğŸ¯ ìµœì¢… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸")
            revised_prompt = st.session_state.revision_results.get('revised_prompt', '')
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.text_area(
                    "ìµœì¢… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸",
                    value=revised_prompt,
                    height=300,
                    disabled=True
                )
            
            with col2:
                if st.button("ğŸ“‹ ë³µì‚¬", use_container_width=True, key="copy_optimized_prompt"):
                    st.write("í´ë¦½ë³´ë“œ ë³µì‚¬ëŠ” ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.")
                
                st.download_button(
                    label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                    data=revised_prompt,
                    file_name="revised_prompt.txt",
                    mime="text/plain",
                    use_container_width=True
                )
            
            # Before/After ë¹„êµ
            st.subheader("ğŸ”„ ê°œì„  ì „í›„ ë¹„êµ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ê°œì„  ì „ (ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸)**")
                st.code(current_prompt, language='text')
            
            with col2:
                st.markdown("**ê°œì„  í›„ (í”¼ë“œë°± ë°˜ì˜)**")
                st.code(revised_prompt, language='text')
            
            # ì¶”ê°€ í”¼ë“œë°± ë²„íŠ¼
            st.markdown("---")
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button(get_text("additional_feedback"), use_container_width=True, key="additional_feedback_btn"):
                    # í˜„ì¬ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒˆë¡œìš´ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
                    st.session_state.optimization_results['optimized_prompt'] = revised_prompt
                    st.session_state.revision_results = None
                    st.session_state.feedback_progress = []
                    st.rerun()
            
            with col2:
                if st.button(get_text("improvement_complete"), type="primary", use_container_width=True, key="improvement_complete_btn"):
                    st.success(get_text("improvement_finished_msg"))
                    st.balloons()
        
    else:
        st.info("ğŸ’¡ ìµœì í™” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'í”„ë¡¬í”„íŠ¸ ì…ë ¥' íƒ­ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”í•´ì£¼ì„¸ìš”.")
        
        # í”„ë¡¬í”„íŠ¸ ìµœì í™”ë¡œ ì´ë™í•˜ëŠ” ë²„íŠ¼
        if st.button(get_text("go_to_input"), use_container_width=True, key="go_to_input_btn"):
            st.switch_page("í”„ë¡¬í”„íŠ¸ ì…ë ¥")

# í‘¸í„°
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>ğŸš€ GPT-4.1 Prompt Optimizer | 
    <a href='https://cookbook.openai.com/examples/gpt4-1_prompting_guide' target='_blank'>OpenAI GPT-4.1 Guide</a> ê¸°ë°˜
    </p>
</div>
""", unsafe_allow_html=True) 