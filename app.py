import streamlit as st
import asyncio
import json
from typing import List, Dict, Any
import time
from prompt_optimizer import (
    optimize_prompt_comprehensive, 
    revise_prompt_with_feedback,
    run_general_agent,
    ChatMessage, 
    Role
)
from language_config import LANGUAGES, TEXTS

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="GPT-4.1 Prompt Optimizer",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì–¸ì–´ ì„¤ì • ì´ˆê¸°í™”
if 'language' not in st.session_state:
    st.session_state.language = 'ko'

def get_text(key: str) -> str:
    """í˜„ì¬ ì„ íƒëœ ì–¸ì–´ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ë°˜í™˜"""
    return TEXTS[st.session_state.language].get(key, key)

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title(get_text("sidebar_title"))
st.sidebar.markdown("---")

# ì–¸ì–´ ì„ íƒ
st.sidebar.subheader(get_text("language_select"))
selected_language = st.sidebar.selectbox(
    "Select Language / ì–¸ì–´ ì„ íƒ",
    options=list(LANGUAGES.keys()),
    index=0 if st.session_state.language == 'ko' else 1,
    key="language_selector"
)

# ì–¸ì–´ ë³€ê²½ ì‹œ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
if LANGUAGES[selected_language] != st.session_state.language:
    st.session_state.language = LANGUAGES[selected_language]
    st.rerun()

st.sidebar.markdown("---")

# OpenAI API ì„¤ì •
st.sidebar.subheader(get_text("openai_settings"))

# API í‚¤ ì…ë ¥
api_key = st.sidebar.text_input(
    get_text("api_key_input"),
    type="password",
    help=get_text("api_key_help")
)

# GPT ëª¨ë¸ ì„ íƒ
gpt_model = st.sidebar.selectbox(
    get_text("model_select"),
    [
        "gpt-4o-mini",
        "gpt-4o", 
        "gpt-4.1",
        "gpt-4-turbo",
        "gpt-4",
        "gpt-3.5-turbo"
    ],
    index=0,
    help=get_text("model_help")
)

# API í‚¤ ìƒíƒœ í‘œì‹œ
if api_key:
    st.sidebar.success(get_text("api_key_set"))
else:
    st.sidebar.warning(get_text("api_key_warning"))

st.sidebar.markdown("---")

# ì—°ë½ì²˜ ì •ë³´
st.sidebar.subheader(get_text("contact_info"))
st.sidebar.markdown(get_text("contact_text"))

st.sidebar.markdown("---")

# OpenAI Cookbook ì°¸ê³  ëª…ì‹œ
st.sidebar.subheader(get_text("reference_materials"))
st.sidebar.markdown(get_text("reference_text"))

st.sidebar.markdown("---")

# ë²„ì „ ì •ë³´
st.sidebar.caption(get_text("version"))

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'optimization_results' not in st.session_state:
    st.session_state.optimization_results = None
if 'progress_messages' not in st.session_state:
    st.session_state.progress_messages = []
if 'few_shot_messages' not in st.session_state:
    st.session_state.few_shot_messages = []
if 'revision_results' not in st.session_state:
    st.session_state.revision_results = None
if 'feedback_progress' not in st.session_state:
    st.session_state.feedback_progress = []
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

def add_progress_message(message: str):
    """ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ì¶”ê°€"""
    st.session_state.progress_messages.append({
        'timestamp': time.time(),
        'message': message
    })

def highlight_differences(original: str, modified: str):
    """ì›ë³¸ê³¼ ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ì˜ ì°¨ì´ì ì„ í•˜ì´ë¼ì´íŠ¸"""
    import difflib
    import html
    import re
    
    # HTML ì´ìŠ¤ì¼€ì´í•‘
    original_escaped = html.escape(original)
    modified_escaped = html.escape(modified)
    
    # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í•  (ë” ì•ˆì „í•œ ë°©ì‹)
    original_words = re.findall(r'\S+|\s+', original)
    modified_words = re.findall(r'\S+|\s+', modified)
    
    # ì°¨ì´ì  ê³„ì‚°
    try:
        diff = list(difflib.unified_diff(original_words, modified_words, lineterm=''))
        
        # ì¶”ê°€ëœ/ì œê±°ëœ ë‹¨ì–´ë“¤ ì°¾ê¸° (ê³µë°± ì œì™¸)
        added_words = [line[1:].strip() for line in diff if line.startswith('+') and not line.startswith('+++') and line[1:].strip()]
        removed_words = [line[1:].strip() for line in diff if line.startswith('-') and not line.startswith('---') and line[1:].strip()]
        
        highlighted_original = original_escaped
        highlighted_modified = modified_escaped
        
        # ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ì—ì„œ ìƒˆë¡œìš´ ë‚´ìš© í•˜ì´ë¼ì´íŠ¸ (ì–´ë‘ìš´ í…Œë§ˆìš©)
        for word in added_words[:5]:  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ
            if word and len(word) > 2:  # ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë§Œ
                word_escaped = html.escape(word)
                highlighted_modified = highlighted_modified.replace(
                    word_escaped, 
                    f"<mark style='background-color: #2d5a27; color: #81c784; padding: 3px 5px; border-radius: 4px; font-weight: bold;'>{word_escaped}</mark>"
                )
        
        # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì œê±°ëœ ë‚´ìš© í•˜ì´ë¼ì´íŠ¸ (ì–´ë‘ìš´ í…Œë§ˆìš©)
        for word in removed_words[:5]:  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ
            if word and len(word) > 2:  # ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë§Œ
                word_escaped = html.escape(word)
                highlighted_original = highlighted_original.replace(
                    word_escaped, 
                    f"<mark style='background-color: #5c1e1e; color: #ef5350; padding: 3px 5px; border-radius: 4px; font-weight: bold;'>{word_escaped}</mark>"
                )
                
        return highlighted_original, highlighted_modified
        
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ë°˜í™˜
        return original_escaped, modified_escaped

def add_feedback_progress(message: str):
    """í”¼ë“œë°± ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ì¶”ê°€"""
    st.session_state.feedback_progress.append({
        'timestamp': time.time(),
        'message': message
    })

async def run_optimization(prompt: str, few_shot_messages: List[ChatMessage] = None, api_key: str = None, model: str = "gpt-4o"):
    """ë¹„ë™ê¸° ìµœì í™” ì‹¤í–‰"""
    st.session_state.progress_messages = []
    
    def progress_callback(message: str):
        add_progress_message(message)
        # Streamlit ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ rerunì€ ë³„ë„ ì²˜ë¦¬
    
    try:
        results = await optimize_prompt_comprehensive(
            prompt=prompt,
            few_shot_messages=few_shot_messages,
            progress_callback=progress_callback,
            api_key=api_key,
            model=model
        )
        st.session_state.optimization_results = results
        add_progress_message("âœ… ìµœì í™” ì™„ë£Œ!")
        return results
    except Exception as e:
        add_progress_message(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

async def run_feedback_revision(optimized_prompt: str, user_feedback: str, api_key: str = None, model: str = "gpt-4o"):
    """í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê°œì„  ì‹¤í–‰"""
    st.session_state.feedback_progress = []
    
    def feedback_progress_callback(message: str):
        add_feedback_progress(message)
    
    try:
        results = await revise_prompt_with_feedback(
            optimized_prompt=optimized_prompt,
            user_feedback=user_feedback,
            progress_callback=feedback_progress_callback,
            api_key=api_key,
            model=model
        )
        st.session_state.revision_results = results
        add_feedback_progress("âœ… í”¼ë“œë°± ê¸°ë°˜ ê°œì„  ì™„ë£Œ!")
        return results
    except Exception as e:
        add_feedback_progress(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def display_severity_badge(severity: str):
    """ì‹¬ê°ë„ ë°°ì§€ í‘œì‹œ"""
    colors = {
        "low": "ğŸŸ¢",
        "medium": "ğŸŸ¡", 
        "high": "ğŸ”´"
    }
    return f"{colors.get(severity, 'âšª')} {severity.upper()}"

def display_category_badge(category: str):
    """ì¹´í…Œê³ ë¦¬ ë°°ì§€ í‘œì‹œ"""
    emoji_map = {
        "clarity": "ğŸ“‹",
        "specificity": "ğŸ¯",
        "instruction_following": "ğŸ“",
        "agentic_capabilities": "ğŸ¤–"
    }
    return f"{emoji_map.get(category, 'ğŸ“')} {category.replace('_', ' ').title()}"

# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
st.title(get_text("main_title"))
st.markdown(get_text("main_description"))

# OpenAI Cookbook ì°¸ê³  ëª…ì‹œ
st.info(get_text("reference_info"))

# íƒ­ ìƒì„±
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    get_text("tab_input"), 
    get_text("tab_progress"), 
    get_text("tab_analysis"), 
    get_text("tab_optimization"),
    get_text("tab_feedback")
])

# íƒ­ 1: í”„ë¡¬í”„íŠ¸ ì…ë ¥
with tab1:
    st.header(get_text("prompt_input_header"))
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader(get_text("main_prompt"))
        user_prompt = st.text_area(
            get_text("main_prompt"),
            height=300,
            placeholder=get_text("prompt_placeholder"),
            help=get_text("prompt_help")
        )
        
        # ìµœì í™” ì‹¤í–‰ ë²„íŠ¼ì„ ì™¼ìª½ ì—´ í•˜ë‹¨ì— ë°°ì¹˜
        st.markdown("---")
        if st.button(get_text("start_optimization"), type="primary", use_container_width=True, key="start_optimization_btn"):
            if not api_key:
                st.error(get_text("api_key_required"))
            elif user_prompt.strip():
                # Few-shot ë©”ì‹œì§€ ë³€í™˜
                few_shot_chat_messages = []
                for msg in st.session_state.few_shot_messages:
                    if msg['content'].strip():
                        few_shot_chat_messages.append(
                            ChatMessage(role=Role(msg['role']), content=msg['content'])
                        )
                
                # ë¹„ë™ê¸° ìµœì í™” ì‹¤í–‰
                with st.spinner(get_text("optimizing_prompt")):
                    results = asyncio.run(run_optimization(
                        prompt=user_prompt,
                        few_shot_messages=few_shot_chat_messages if few_shot_chat_messages else None,
                        api_key=api_key,
                        model=gpt_model
                    ))
                
                if results:
                    st.success(get_text("optimization_complete"))
                    st.balloons()
                else:
                    st.error(get_text("optimization_error"))
            else:
                st.error(get_text("prompt_required"))
    
    with col2:
        st.subheader(get_text("prompt_type"))
        prompt_type = st.selectbox(
            get_text("prompt_type"),
            get_text("prompt_type_options")
        )
        
        st.subheader(get_text("advanced_settings"))
        include_agentic = st.checkbox(
            get_text("agentic_enhancement"),
            help=get_text("agentic_help")
        )
        
        optimize_for_tools = st.checkbox(
            get_text("tool_optimization"),
            help=get_text("tool_help")
        )
        
        # Few-shot ì˜ˆì œë¥¼ ì˜¤ë¥¸ìª½ ì—´ë¡œ ì´ë™
        st.markdown("---")
        st.subheader(get_text("few_shot_examples"))
        st.markdown(get_text("few_shot_description"))
        
        col3, col4 = st.columns(2)
        
        with col3:
            if st.button(get_text("add_example"), key="add_example_btn"):
                st.session_state.few_shot_messages.append({
                    'role': 'user',
                    'content': ''
                })
                st.session_state.few_shot_messages.append({
                    'role': 'assistant', 
                    'content': ''
                })
        
        with col4:
            if st.button(get_text("delete_examples"), key="delete_examples_btn"):
                st.session_state.few_shot_messages = []
        
        # Few-shot ì˜ˆì œ ì…ë ¥
        if st.session_state.few_shot_messages:
            st.markdown(get_text("few_shot_examples_header"))
            for i in range(0, len(st.session_state.few_shot_messages), 2):
                st.session_state.few_shot_messages[i]['content'] = st.text_area(
                    f"{get_text('user_message')} {i//2 + 1}",
                    value=st.session_state.few_shot_messages[i]['content'],
                    key=f"user_{i}",
                    height=80
                )
                
                if i + 1 < len(st.session_state.few_shot_messages):
                    st.session_state.few_shot_messages[i+1]['content'] = st.text_area(
                        f"{get_text('assistant_response')} {i//2 + 1}",
                        value=st.session_state.few_shot_messages[i+1]['content'],
                        key=f"assistant_{i+1}",
                        height=80
                    )

# íƒ­ 2: ë¶„ì„ ì§„í–‰
with tab2:
    st.header("ğŸ” ë¶„ì„ ì§„í–‰ ìƒí™©")
    
    if st.session_state.progress_messages:
        st.subheader("ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©")
        
        # ì§„í–‰ ìƒí™© ì»¨í…Œì´ë„ˆ
        progress_container = st.container()
        
        with progress_container:
            for i, msg in enumerate(st.session_state.progress_messages):
                timestamp = time.strftime("%H:%M:%S", time.localtime(msg['timestamp']))
                st.write(f"`{timestamp}` {msg['message']}")
        
        # ì§„í–‰ë¥  ê³„ì‚° (ëŒ€ëµì )
        total_steps = 8  # ì˜ˆìƒ ì´ ë‹¨ê³„
        current_step = len(st.session_state.progress_messages)
        progress = min(current_step / total_steps, 1.0)
        
        st.progress(progress)
        st.caption(f"ì§„í–‰ë¥ : {progress * 100:.0f}%")
        
        # ìë™ ìƒˆë¡œê³ ì¹¨
        if progress < 1.0:
            time.sleep(1)
            st.rerun()
    else:
        st.info("ğŸ’¡ 'í”„ë¡¬í”„íŠ¸ ì…ë ¥' íƒ­ì—ì„œ ìµœì í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
        
        # ìƒ˜í”Œ ì§„í–‰ ìƒí™© í‘œì‹œ
        st.subheader("ì˜ˆìƒ ë¶„ì„ ë‹¨ê³„")
        sample_steps = [
            "ğŸš€ ì¢…í•©ì  í”„ë¡¬í”„íŠ¸ ë¶„ì„ ì‹œì‘...",
            "ğŸ” Agent 'clarity_checker' ì‹¤í–‰ ì¤‘...",
            "ğŸ“‹ ëª…í™•ì„± ë¶„ì„ ì¤‘...",
            "âœ… ëª…í™•ì„± ë¶„ì„ ì™„ë£Œ",
            "ğŸ¯ êµ¬ì²´ì„± ë¶„ì„ ì¤‘...",
            "âœ… êµ¬ì²´ì„± ë¶„ì„ ì™„ë£Œ",
            "ğŸ“ ì§€ì‹œì‚¬í•­ ì¤€ìˆ˜ ë¶„ì„ ì¤‘...",
            "âœ… ì§€ì‹œì‚¬í•­ ì¤€ìˆ˜ ë¶„ì„ ì™„ë£Œ",
            "ğŸ¤– ì—ì´ì „í‹± ëŠ¥ë ¥ ë¶„ì„ ì¤‘...",
            "âœ… ì—ì´ì „í‹± ëŠ¥ë ¥ ë¶„ì„ ì™„ë£Œ",
            "ğŸ“Š ë¶„ì„ ì™„ë£Œ: ì´ ë¬¸ì œ ì§‘ê³„",
            "âœï¸ í”„ë¡¬í”„íŠ¸ ìµœì í™” ì¤‘...",
            "âœ… í”„ë¡¬í”„íŠ¸ ìµœì í™” ì™„ë£Œ",
            "âœ… ìµœì í™” ì™„ë£Œ!"
        ]
        
        for step in sample_steps:
            st.text(step)

# íƒ­ 3: ë¶„ì„ ê²°ê³¼
with tab3:
    st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    if st.session_state.optimization_results:
        results = st.session_state.optimization_results
        
        # ìš”ì•½ ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ë°œê²¬ëœ ë¬¸ì œ",
                results.get('total_issues_found', 0),
                delta=None
            )
        
        with col2:
            st.metric(
                "ì˜ˆìƒ ê°œì„ ìœ¨",
                f"{results.get('estimated_improvement', 0):.0f}%",
                delta=f"+{results.get('estimated_improvement', 0):.0f}%"
            )
        
        with col3:
            analysis_results = results.get('analysis_results', [])
            high_severity = sum(1 for r in analysis_results if r.get('severity') == 'high')
            st.metric(
                "ê³ ìœ„í—˜ ë¬¸ì œ",
                high_severity,
                delta=f"-{high_severity}" if high_severity > 0 else None
            )
        
        with col4:
            changes_made = results.get('optimization_details', {}).get('changes_made', [])
            st.metric(
                "ì ìš©ëœ ê°œì„ ì‚¬í•­",
                len(changes_made),
                delta=f"+{len(changes_made)}"
            )
        
        st.markdown("---")
        
        # ìƒì„¸ ë¶„ì„ ê²°ê³¼
        st.subheader("ğŸ” ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        
        original_prompt = results.get('original_prompt', '')
        
        for i, analysis in enumerate(analysis_results):
            category = analysis.get('category', 'general')
            severity = analysis.get('severity', 'medium')
            issues = analysis.get('issues', [])
            
            if issues:
                with st.expander(f"{display_category_badge(category)} - {display_severity_badge(severity)} ({len(issues)}ê°œ ë¬¸ì œ)"):
                    for j, issue in enumerate(issues, 1):
                        st.markdown(f"""
                        <div style="background-color: #ffeb3b22; padding: 8px; border-left: 3px solid #ff9800; margin: 5px 0;">
                            <strong>{j}. ğŸ” ë°œê²¬ëœ ë¬¸ì œ:</strong><br>
                            {issue}
                        </div>
                        """, unsafe_allow_html=True)
                        
                                                # ë¬¸ì œì™€ ê´€ë ¨ëœ í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ ì¸ìš© ë° ë¶„ì„ (ëŒ€í­ ê°œì„ )
                        st.markdown("**ğŸ“‹ ì›ë³¸ í”„ë¡¬í”„íŠ¸ì—ì„œ í•´ë‹¹ ë¬¸ì œ ë¶€ë¶„ ë¶„ì„:**")
                        
                        # ë¬¸ì œ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ ì›ë³¸ í”„ë¡¬í”„íŠ¸ì—ì„œ ì°¾ê¸°
                        issue_lower = issue.lower()
                        found_problems = []
                        
                        # 1. ëª¨ìˆœ/ì¶©ëŒ ê°ì§€
                        if 'contradictory' in issue_lower or 'conflict' in issue_lower or 'ëª¨ìˆœ' in issue_lower:
                            # ìƒì¶©ë˜ëŠ” ì§€ì‹œì‚¬í•­ ì°¾ê¸°
                            if 'missing' in issue_lower and 'error' in issue_lower and 'null' in issue_lower:
                                # required field ê´€ë ¨ ëª¨ìˆœ
                                conflict_parts = []
                                lines = original_prompt.split('\n')
                                for i, line in enumerate(lines):
                                    if 'required' in line.lower() and ('missing' in line.lower() or 'error' in line.lower()):
                                        conflict_parts.append(f"ë¼ì¸ {i+1}: {line.strip()}")
                                    elif 'null' in line.lower() and 'acceptable' in line.lower():
                                        conflict_parts.append(f"ë¼ì¸ {i+1}: {line.strip()}")
                                
                                if conflict_parts:
                                    found_problems.append({
                                        'type': 'ìƒì¶©ë˜ëŠ” ì§€ì‹œì‚¬í•­',
                                        'parts': conflict_parts,
                                        'explanation': 'í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ì‹œ ì—ëŸ¬ ì²˜ë¦¬ì™€ null í—ˆìš© ì§€ì‹œê°€ ì¶©ëŒ'
                                    })
                        
                        # 2. êµ¬ë¬¸/í˜•ì‹ ì˜¤ë¥˜ ê°ì§€
                        if 'json' in issue_lower and ('not properly closed' in issue_lower or 'missing' in issue_lower):
                            # JSON êµ¬ì¡° ë¬¸ì œ ì°¾ê¸°
                            json_parts = []
                            lines = original_prompt.split('\n')
                            in_json = False
                            brace_count = 0
                            
                            for i, line in enumerate(lines):
                                if '{' in line:
                                    in_json = True
                                    brace_count += line.count('{')
                                if in_json:
                                    brace_count -= line.count('}')
                                    json_parts.append(f"ë¼ì¸ {i+1}: {line.strip()}")
                                    if brace_count == 0:
                                        break
                            
                            if json_parts and brace_count > 0:
                                found_problems.append({
                                    'type': 'JSON êµ¬ì¡° ì˜¤ë¥˜',
                                    'parts': json_parts[-3:] if len(json_parts) > 3 else json_parts,
                                    'explanation': f'JSON ë‹«ëŠ” ê´„í˜¸ ëˆ„ë½ (í˜„ì¬ ê· í˜•: {brace_count})'
                                })
                        
                        # 3. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ë¬¸ì œ
                        if 'markdown' in issue_lower and 'backticks' in issue_lower:
                            markdown_parts = []
                            lines = original_prompt.split('\n')
                            for i, line in enumerate(lines):
                                if '```' in line:
                                    markdown_parts.append(f"ë¼ì¸ {i+1}: {line.strip()}")
                            
                            if markdown_parts:
                                found_problems.append({
                                    'type': 'ë§ˆí¬ë‹¤ìš´ í˜•ì‹ í˜¼ë€',
                                    'parts': markdown_parts,
                                    'explanation': 'ì¶œë ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹ í¬í•¨'
                                })
                        
                        # 4. ëª¨í˜¸í•œ ìš©ì–´/ì§€ì‹œì‚¬í•­
                        if 'ambiguity' in issue_lower or 'unclear' in issue_lower or 'ëª¨í˜¸' in issue_lower:
                            ambiguous_parts = []
                            
                            # êµ¬ì²´ì ì¸ ëª¨í˜¸í•œ ë¶€ë¶„ ì°¾ê¸°
                            if 'synonyms' in issue_lower:
                                lines = original_prompt.split('\n')
                                for i, line in enumerate(lines):
                                    if 'synonym' in line.lower() or 'collapse' in line.lower():
                                        ambiguous_parts.append(f"ë¼ì¸ {i+1}: {line.strip()}")
                            
                            if 'care_instructions' in issue_lower or 'features' in issue_lower:
                                lines = original_prompt.split('\n')
                                for i, line in enumerate(lines):
                                    if 'care_instructions' in line or 'features' in line:
                                        ambiguous_parts.append(f"ë¼ì¸ {i+1}: {line.strip()}")
                            
                            if ambiguous_parts:
                                found_problems.append({
                                    'type': 'ëª¨í˜¸í•œ ì§€ì‹œì‚¬í•­',
                                    'parts': ambiguous_parts,
                                    'explanation': 'êµ¬ì²´ì ì¸ ì²˜ë¦¬ ë°©ë²•ì´ë‚˜ ì˜ˆì‹œê°€ ë¶€ì¡±í•œ ì§€ì‹œì‚¬í•­'
                                })
                        
                        # ë¬¸ì œ ë¶€ë¶„ë“¤ í‘œì‹œ
                        if found_problems:
                            for prob_idx, problem in enumerate(found_problems, 1):
                                st.markdown(f"""
                                <div style="background-color: #fff3e0; border-left: 4px solid #ff9800; padding: 12px; margin: 8px 0; border-radius: 5px;">
                                    <strong>ğŸ¯ {problem['type']} #{prob_idx}</strong><br>
                                    <em style="color: #f57c00;">{problem['explanation']}</em>
                                </div>
                                """, unsafe_allow_html=True)
                                
                                st.markdown("**í•´ë‹¹ í”„ë¡¬í”„íŠ¸ ë¶€ë¶„:**")
                                for part in problem['parts']:
                                    st.code(part, language='text')
                        else:
                            # ê¸°ë³¸ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ (ê¸°ì¡´ ë¡œì§ ë‹¨ìˆœí™”)
                            problem_keywords = []
                            if 'unclear' in issue_lower: problem_keywords.extend(['maybe', 'perhaps', 'might'])
                            if 'missing' in issue_lower: problem_keywords.extend(['task', 'goal', 'format'])
                            if 'ambiguous' in issue_lower: problem_keywords.extend(['this', 'that', 'it'])
                            
                            if problem_keywords:
                                lines = original_prompt.split('\n')
                                matching_lines = []
                                for i, line in enumerate(lines):
                                    if any(keyword in line.lower() for keyword in problem_keywords):
                                        matching_lines.append(f"ë¼ì¸ {i+1}: {line.strip()}")
                                
                                if matching_lines:
                                    st.markdown("**ê´€ë ¨ ê°€ëŠ¥ì„±ì´ ìˆëŠ” í”„ë¡¬í”„íŠ¸ ë¶€ë¶„:**")
                                    for line in matching_lines[:3]:  # ìµœëŒ€ 3ê°œ
                                        st.code(line, language='text')
                                else:
                                    st.info("ğŸ’¡ í•´ë‹¹ ë¬¸ì œëŠ” ì „ì²´ì ì¸ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ë‚˜ ë‚´ìš©ì˜ ë§¥ë½ê³¼ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.success(f"{display_category_badge(category)} - ë¬¸ì œ ì—†ìŒ âœ…")
        
        # ì›ë³¸ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
        st.subheader("ğŸ“ ì›ë³¸ í”„ë¡¬í”„íŠ¸")
        with st.expander("ì›ë³¸ í”„ë¡¬í”„íŠ¸ ë³´ê¸°"):
            st.code(results.get('original_prompt', ''), language='text')
    
    else:
        st.info("ğŸ’¡ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”í•´ì£¼ì„¸ìš”.")

# íƒ­ 4: ìµœì í™” ê²°ê³¼
with tab4:
    st.header("âœ¨ ìµœì í™” ê²°ê³¼")
    
    if st.session_state.optimization_results:
        results = st.session_state.optimization_results
        optimization_details = results.get('optimization_details', {})
        
        # ë³€ê²½ì‚¬í•­ ë¹„êµ (ìœ„ë¡œ ì´ë™)
        st.subheader("ğŸ”„ ë³€ê²½ì‚¬í•­ ë¹„êµ")
        
        original_prompt = results.get('original_prompt', '')
        optimized_prompt = results.get('optimized_prompt', '')
        changes_made = optimization_details.get('changes_made', [])
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ“ ì›ë³¸ í”„ë¡¬í”„íŠ¸**")
            # Streamlit code ë¸”ë¡ ì‚¬ìš© (ì–´ë‘ìš´ ë°°ê²½ ìë™ ì ìš©)
            st.code(original_prompt, language='text', line_numbers=False)
        
        with col2:
            st.markdown("**âœ¨ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸**")
            # Streamlit code ë¸”ë¡ ì‚¬ìš© (ì–´ë‘ìš´ ë°°ê²½ ìë™ ì ìš©)
            st.code(optimized_prompt, language='text', line_numbers=False)
        
        # ì°¨ì´ì  í•˜ì´ë¼ì´íŠ¸ ì„¹ì…˜
        with st.expander("ğŸ” ì°¨ì´ì  í•˜ì´ë¼ì´íŠ¸ ë³´ê¸° (ì‹¤í—˜ì  ê¸°ëŠ¥)"):
            st.info("ğŸ’¡ ì´ ê¸°ëŠ¥ì€ ì‹¤í—˜ì ì´ë©°, ë³µì¡í•œ í…ìŠ¤íŠ¸ì—ì„œëŠ” ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            try:
                highlighted_original, highlighted_modified = highlight_differences(original_prompt, optimized_prompt)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ì›ë³¸ (ë¹¨ê°„ìƒ‰: ì œê±°ë¨)**")
                    if highlighted_original != original_prompt:
                        st.markdown(f"""
                        <div style="background-color: #2d3748; border: 1px solid #4a5568; border-radius: 8px; padding: 15px; height: 250px; overflow-y: auto; font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace; white-space: pre-wrap; color: #e2e8f0; line-height: 1.6; font-size: 13px;">
                        {highlighted_original}
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.code(original_prompt, language='text')
                
                with col2:
                    st.markdown("**ìµœì í™”ë¨ (ì´ˆë¡ìƒ‰: ì¶”ê°€ë¨)**")
                    if highlighted_modified != optimized_prompt:
                        st.markdown(f"""
                        <div style="background-color: #2d3748; border: 1px solid #4a5568; border-radius: 8px; padding: 15px; height: 250px; overflow-y: auto; font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace; white-space: pre-wrap; color: #e2e8f0; line-height: 1.6; font-size: 13px;">
                        {highlighted_modified}
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.code(optimized_prompt, language='text')
                        
            except Exception as e:
                st.error(f"ì°¨ì´ì  ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                
                # í´ë°±: ì¼ë°˜ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ í‘œì‹œ
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ì›ë³¸**")
                    st.code(original_prompt, language='text')
                with col2:
                    st.markdown("**ìµœì í™”ë¨**")
                    st.code(optimized_prompt, language='text')
        
        # í•˜ì´ë¼ì´íŠ¸ëœ ë³€ê²½ì‚¬í•­ ì„¤ëª…
        if changes_made:
            st.markdown("### ğŸ¯ ì£¼ìš” ë³€ê²½ì‚¬í•­")
            for i, change in enumerate(changes_made, 1):
                st.markdown(f"""
                <div style="background-color: #ffeb3b33; padding: 10px; border-left: 4px solid #ffeb3b; margin: 5px 0;">
                    <strong>{i}. âœ… {change}</strong>
                </div>
                """, unsafe_allow_html=True)
        
        # ê°œì„ ì‚¬í•­ ìš”ì•½ (ë¶„ì„ê²°ê³¼ì™€ í†µí•©)
        st.subheader("ğŸ“ˆ ì¢…í•© ë¶„ì„ ë° ê°œì„  ìš”ì•½")
        
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col1:
            st.info(f"**ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ **: {optimization_details.get('estimated_improvement', 0):.0f}%")
            
        with col2:
            st.success(f"**ì ìš©ëœ ê°œì„ ì‚¬í•­**: {len(changes_made)}ê°œ")
            
        with col3:
            # ë¶„ì„ ê²°ê³¼ì—ì„œ ë°œê²¬ëœ ì´ ë¬¸ì œ ê°œìˆ˜
            if hasattr(st.session_state, 'analysis_results') and st.session_state.analysis_results:
                analysis_results = st.session_state.analysis_results
                total_issues = sum(len(result.get('issues', [])) for result in analysis_results.get('analysis_details', []))
                st.warning(f"**í•´ê²°ëœ ë¬¸ì œ**: {total_issues}ê°œ")
            else:
                st.info("**ë¶„ì„ ì •ë³´**: ì—†ìŒ")
        
        # ê°œì„  ì„¤ëª…
        improvement_explanation = optimization_details.get('improvement_explanation', '')
        if improvement_explanation:
            st.subheader("ğŸ’¡ ê°œì„  ì„¤ëª…")
            st.write(improvement_explanation)
        
        st.markdown("---")
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸ì™€ ë²„íŠ¼ë“¤
        st.subheader("ğŸ“¥ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸")
        
        # í”„ë¡¬í”„íŠ¸ì™€ ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.text_area(
                "ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸",
                value=optimized_prompt,
                height=250,
                disabled=False,
                help="ì´ ì˜ì—­ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ì—¬ ë³µì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                label_visibility="collapsed"
            )
        
        with col2:
            st.markdown("**ğŸ“‹ ë‚´ë³´ë‚´ê¸°**")
            if st.button("ğŸ“‹ ë³µì‚¬", use_container_width=True, key="copy_final_prompt"):
                st.success("ğŸ“ ì™¼ìª½ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ì—¬ ë³µì‚¬í•˜ì„¸ìš”!")
            
            st.download_button(
                label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                data=optimized_prompt,
                file_name="optimized_prompt.txt",
                mime="text/plain",
                use_container_width=True
            )

        
        # Few-shot ì˜ˆì œ ìµœì í™” (ìˆëŠ” ê²½ìš°)
        optimized_messages = results.get('optimized_messages', [])
        if optimized_messages:
            st.subheader("ğŸ’¬ ìµœì í™”ëœ Few-shot ì˜ˆì œ")
            
            for i, msg in enumerate(optimized_messages):
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
                
                if role == 'user':
                    st.markdown(f"**ì‚¬ìš©ì {i//2 + 1}:**")
                    st.info(content)
                elif role == 'assistant':
                    st.markdown(f"**ì–´ì‹œìŠ¤í„´íŠ¸ {(i+1)//2}:**")
                    st.success(content)
        
        # ì¬ì‹œì‘ ë²„íŠ¼
        st.markdown("---")
        if st.button(get_text("new_optimization"), type="secondary", use_container_width=True, key="new_optimization_btn"):
            st.session_state.optimization_results = None
            st.session_state.progress_messages = []
            st.session_state.few_shot_messages = []
            st.rerun()
    
    else:
        st.info("ğŸ’¡ ìµœì í™” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”í•´ì£¼ì„¸ìš”.")

# íƒ­ 5: í”¼ë“œë°± & ë¦¬ë¹„ì „
with tab5:
    st.header("ğŸ”„ í”¼ë“œë°± & ë¦¬ë¹„ì „")
    
    if st.session_state.optimization_results:
        # í˜„ì¬ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
        st.subheader("ğŸ“ í˜„ì¬ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸")
        current_prompt = st.session_state.optimization_results.get('optimized_prompt', '')
        
        with st.expander("í˜„ì¬ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ë³´ê¸°", expanded=False):
            st.code(current_prompt, language='text')
        
        st.markdown("---")
        
        # í”¼ë“œë°± ì…ë ¥ ì„¹ì…˜
        st.subheader("ğŸ’¬ í”¼ë“œë°± ì œê³µ")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            user_feedback = st.text_area(
                "ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì‘ì„±í•´ì£¼ì„¸ìš”",
                height=150,
                placeholder="""ì˜ˆì‹œ í”¼ë“œë°±:
â€¢ í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ë³µì¡í•´ ë³´ì…ë‹ˆë‹¤. ë” ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
â€¢ ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ì§€ì¹¨ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.
â€¢ ì‘ë‹µì´ ë„ˆë¬´ ì§§ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë” ìƒì„¸í•œ ë‹µë³€ì„ ìš”êµ¬í•´ì£¼ì„¸ìš”.
â€¢ íŠ¹ì • í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ë„ë¡ ëª…ì‹œí•´ì£¼ì„¸ìš”.
â€¢ ê³„íš ìˆ˜ë¦½ ë‹¨ê³„ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.""",
                help="êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí• ìˆ˜ë¡ ë” ë‚˜ì€ ê°œì„  ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        
        with col2:
            st.subheader("í”¼ë“œë°± ì¹´í…Œê³ ë¦¬")
            feedback_category = st.selectbox(
                "í”¼ë“œë°± ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”",
                [
                    "ì¼ë°˜ì ì¸ ê°œì„ ì‚¬í•­",
                    "ëª…í™•ì„± ê°œì„ ",
                    "êµ¬ì²´ì„± ê°œì„ ", 
                    "ì§€ì‹œì‚¬í•­ ìˆ˜ì •",
                    "ì—ì´ì „í‹± ëŠ¥ë ¥ ê°œì„ ",
                    "í˜•ì‹ ê°œì„ ",
                    "ê¸°íƒ€"
                ]
            )
            
            feedback_priority = st.selectbox(
                "ìš°ì„ ìˆœìœ„",
                ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"]
            )
            
            # í”¼ë“œë°± ì˜ˆì‹œ ë²„íŠ¼ë“¤
            st.subheader(get_text("quick_feedback"))
            if st.button(get_text("feedback_complex"), use_container_width=True, key="quick_complex"):
                st.session_state.quick_feedback = get_text("quick_feedback_complex")
            
            if st.button(get_text("feedback_tools"), use_container_width=True, key="quick_tools"):
                st.session_state.quick_feedback = get_text("quick_feedback_tools")
            
            if st.button(get_text("feedback_length"), use_container_width=True, key="quick_length"):
                st.session_state.quick_feedback = get_text("quick_feedback_length")
            
            if st.button(get_text("feedback_planning"), use_container_width=True, key="quick_planning"):
                st.session_state.quick_feedback = get_text("quick_feedback_planning")
        
        # ë¹ ë¥¸ í”¼ë“œë°±ì´ ì„ íƒëœ ê²½ìš° ìë™ ì…ë ¥
        if 'quick_feedback' in st.session_state and st.session_state.quick_feedback:
            user_feedback = st.text_area(
                "ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì‘ì„±í•´ì£¼ì„¸ìš”",
                value=st.session_state.quick_feedback,
                height=150,
                key="feedback_with_quick"
            )
            st.session_state.quick_feedback = None  # ì´ˆê¸°í™”
        
        # í”¼ë“œë°± ê¸°ë°˜ ê°œì„  ì‹¤í–‰
        if st.button(get_text("start_feedback_improvement"), type="primary", use_container_width=True, key="start_feedback_btn"):
            if not api_key:
                st.error(get_text("api_key_required"))
            elif user_feedback.strip():
                with st.spinner("Analyzing feedback and improving prompt..." if st.session_state.language == 'en' else "í”¼ë“œë°±ì„ ë¶„ì„í•˜ê³  í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„  ì¤‘..."):
                    
                    # ë²”ìš© ìš”ì²­ í‚¤ì›Œë“œ ê°ì§€
                    general_keywords = ["í•œê¸€", "ì˜ì–´", "korean", "english", "translate", "ë²ˆì—­", "ë³€ê²½", "formal", "casual", "shorter", "longer", "ì •ì¤‘", "ì¹œê·¼", "ì§§ê²Œ", "ê¸¸ê²Œ", "ê°„ë‹¨", "ìì„¸íˆ"]
                    is_general_request = any(keyword in user_feedback.lower() for keyword in general_keywords)
                    
                    if is_general_request:
                        # ë²”ìš© Agent ì‚¬ìš©
                        general_results = asyncio.run(run_general_agent(
                            original_prompt=current_prompt,
                            user_feedback=user_feedback,
                            api_key=api_key,
                            model=gpt_model
                        ))
                        
                        if general_results:
                            # ë²”ìš© ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                            st.session_state.revision_results = {
                                "original_optimized_prompt": general_results["original_prompt"],
                                "user_feedback": general_results["user_feedback"],
                                "revised_prompt": general_results["modified_prompt"],
                                "changes_made": general_results["changes_made"],
                                "explanation": general_results["explanation"],
                                "feedback_addressed": [general_results["feedback_addressed"]],
                                "revision_details": {
                                    "changes_made": general_results["changes_made"],
                                    "feedback_addressed": [general_results["feedback_addressed"]]
                                }
                            }
                            st.success(get_text("feedback_complete"))
                            st.balloons()
                        else:
                            st.error(get_text("feedback_error"))
                    else:
                        # ê¸°ì¡´ ë¶„ì„ ê¸°ë°˜ ì‹œìŠ¤í…œ ì‚¬ìš©
                        results = asyncio.run(run_feedback_revision(
                            optimized_prompt=current_prompt,
                            user_feedback=user_feedback,
                            api_key=api_key,
                            model=gpt_model
                        ))
                        
                        if results:
                            st.success(get_text("feedback_complete"))
                            st.balloons()
                        else:
                            st.error(get_text("feedback_error"))
            else:
                st.error(get_text("feedback_required"))
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if st.session_state.feedback_progress:
            st.subheader("ğŸ” ê°œì„  ì§„í–‰ ìƒí™©")
            
            with st.container():
                for msg in st.session_state.feedback_progress:
                    timestamp = time.strftime("%H:%M:%S", time.localtime(msg['timestamp']))
                    st.write(f"`{timestamp}` {msg['message']}")
        
        # ë¦¬ë¹„ì „ ê²°ê³¼ í‘œì‹œ
        if st.session_state.revision_results:
            st.markdown("---")
            st.subheader("ğŸ“Š í”¼ë“œë°± ê¸°ë°˜ ê°œì„  ê²°ê³¼")
            
            # ê°œì„  ìš”ì•½
            col1, col2, col3 = st.columns(3)
            
            revision_details = st.session_state.revision_results.get('revision_details', {})
            changes_made = revision_details.get('changes_made', [])
            feedback_addressed = revision_details.get('feedback_addressed', [])
            
            with col1:
                st.metric("ì ìš©ëœ ë³€ê²½ì‚¬í•­", len(changes_made))
            
            with col2:
                st.metric("ì²˜ë¦¬ëœ í”¼ë“œë°±", len(feedback_addressed))
            
            with col3:
                # ê°œì„ ë„ ê³„ì‚° (ë³€ê²½ì‚¬í•­ ìˆ˜ ê¸°ë°˜)
                improvement_score = min(len(changes_made) * 20, 100)
                st.metric("ê°œì„  ì ìˆ˜", f"{improvement_score}%")
            
            # ì ìš©ëœ ë³€ê²½ì‚¬í•­
            if changes_made:
                st.subheader("ğŸ”§ ì ìš©ëœ ë³€ê²½ì‚¬í•­")
                for i, change in enumerate(changes_made, 1):
                    st.write(f"{i}. âœ… {change}")
            
            # ì²˜ë¦¬ëœ í”¼ë“œë°±
            if feedback_addressed:
                st.subheader("ğŸ’¬ ì²˜ë¦¬ëœ í”¼ë“œë°±")
                for i, feedback in enumerate(feedback_addressed, 1):
                    st.write(f"{i}. ğŸ“ {feedback}")
            
            # ê°œì„  ì„¤ëª…
            improvement_explanation = revision_details.get('improvement_explanation', '')
            if improvement_explanation:
                st.subheader("ğŸ’¡ ê°œì„  ì„¤ëª…")
                st.info(improvement_explanation)
            
            # ìµœì¢… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
            st.subheader("ğŸ¯ ìµœì¢… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸")
            revised_prompt = st.session_state.revision_results.get('revised_prompt', '')
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.text_area(
                    "ìµœì¢… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸",
                    value=revised_prompt,
                    height=300,
                    disabled=True
                )
            
            with col2:
                if st.button("ğŸ“‹ ë³µì‚¬", use_container_width=True, key="copy_optimized_prompt"):
                    st.write("í´ë¦½ë³´ë“œ ë³µì‚¬ëŠ” ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.")
                
                st.download_button(
                    label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                    data=revised_prompt,
                    file_name="revised_prompt.txt",
                    mime="text/plain",
                    use_container_width=True
                )
            
            # Before/After ë¹„êµ
            st.subheader("ğŸ”„ ê°œì„  ì „í›„ ë¹„êµ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ê°œì„  ì „ (ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸)**")
                st.code(current_prompt, language='text')
            
            with col2:
                st.markdown("**ê°œì„  í›„ (í”¼ë“œë°± ë°˜ì˜)**")
                st.code(revised_prompt, language='text')
            
            # ì¶”ê°€ í”¼ë“œë°± ë²„íŠ¼
            st.markdown("---")
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button(get_text("additional_feedback"), use_container_width=True, key="additional_feedback_btn"):
                    # í˜„ì¬ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒˆë¡œìš´ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
                    st.session_state.optimization_results['optimized_prompt'] = revised_prompt
                    st.session_state.revision_results = None
                    st.session_state.feedback_progress = []
                    st.rerun()
            
            with col2:
                if st.button(get_text("improvement_complete"), type="primary", use_container_width=True, key="improvement_complete_btn"):
                    st.success(get_text("improvement_finished_msg"))
                    st.balloons()
        
    else:
        st.info("ğŸ’¡ ìµœì í™” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'í”„ë¡¬í”„íŠ¸ ì…ë ¥' íƒ­ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”í•´ì£¼ì„¸ìš”.")
        
        # í”„ë¡¬í”„íŠ¸ ìµœì í™”ë¡œ ì´ë™í•˜ëŠ” ë²„íŠ¼
        if st.button(get_text("go_to_input"), use_container_width=True, key="go_to_input_btn"):
            st.switch_page("í”„ë¡¬í”„íŠ¸ ì…ë ¥")

# í‘¸í„°
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>ğŸš€ GPT-4.1 Prompt Optimizer | 
    <a href='https://cookbook.openai.com/examples/gpt4-1_prompting_guide' target='_blank'>OpenAI GPT-4.1 Guide</a> ê¸°ë°˜
    </p>
</div>
""", unsafe_allow_html=True) 