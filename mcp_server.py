#!/usr/bin/env python3
"""
MCP Server for Prompt Optimizer

ì´ MCP ì„œë²„ëŠ” í”„ë¡¬í”„íŠ¸ ìµœì í™” ê¸°ëŠ¥ì„ ë‹¤ë¥¸ AI í”„ë¡œì íŠ¸ì—ì„œ 
ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í‘œì¤€í™”ëœ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import asyncio
import json
import logging
from typing import Any, Dict, List, Optional, Sequence
from datetime import datetime

from mcp.server import Server
from mcp.server.models import InitializationOptions
from mcp.server.stdio import stdio_server
from mcp.types import (
    CallToolRequest,
    CallToolResult,
    ListToolsRequest,
    ListToolsResult,
    Tool,
    TextContent,
    ImageContent,
    EmbeddedResource,
)

# ìš°ë¦¬ì˜ í”„ë¡¬í”„íŠ¸ ìµœì í™” ëª¨ë“ˆ ì„í¬íŠ¸
from prompt_optimizer import (
    optimize_prompt_comprehensive,
    revise_prompt_with_feedback,
    ChatMessage,
    Role
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("prompt-optimizer-mcp")

class PromptOptimizerMCPServer:
    """í”„ë¡¬í”„íŠ¸ ìµœì í™”ë¥¼ ìœ„í•œ MCP ì„œë²„"""
    
    def __init__(self):
        self.server = Server("prompt-optimizer")
        self.setup_tools()
    
    def setup_tools(self):
        """MCP ë„êµ¬ë“¤ì„ ì„¤ì •í•©ë‹ˆë‹¤"""
        
        @self.server.list_tools()
        async def handle_list_tools() -> list[Tool]:
            """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤"""
            return [
                Tool(
                    name="optimize_prompt",
                    description="GPT-4.1 ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ìµœì í™”í•©ë‹ˆë‹¤",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "prompt": {
                                "type": "string",
                                "description": "ìµœì í™”í•  í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸"
                            },
                            "few_shot_messages": {
                                "type": "array",
                                "description": "Few-shot ì˜ˆì œ ë©”ì‹œì§€ë“¤ (ì„ íƒì‚¬í•­)",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "role": {
                                            "type": "string",
                                            "enum": ["user", "assistant"],
                                            "description": "ë©”ì‹œì§€ ì—­í• "
                                        },
                                        "content": {
                                            "type": "string",
                                            "description": "ë©”ì‹œì§€ ë‚´ìš©"
                                        }
                                    },
                                    "required": ["role", "content"]
                                }
                            },
                            "include_analysis": {
                                "type": "boolean",
                                "description": "ìƒì„¸í•œ ë¶„ì„ ê²°ê³¼ë¥¼ í¬í•¨í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: true)",
                                "default": True
                            }
                        },
                        "required": ["prompt"]
                    }
                ),
                Tool(
                    name="revise_with_feedback",
                    description="ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€ ê°œì„ í•©ë‹ˆë‹¤",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "optimized_prompt": {
                                "type": "string",
                                "description": "ì´ë¯¸ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸"
                            },
                            "user_feedback": {
                                "type": "string",
                                "description": "ì‚¬ìš©ìì˜ í”¼ë“œë°±"
                            },
                            "include_analysis": {
                                "type": "boolean",
                                "description": "í”¼ë“œë°± ë¶„ì„ ê²°ê³¼ë¥¼ í¬í•¨í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: true)",
                                "default": True
                            }
                        },
                        "required": ["optimized_prompt", "user_feedback"]
                    }
                ),
                Tool(
                    name="analyze_prompt",
                    description="í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë¬¸ì œì ë§Œ ì°¾ì•„ëƒ…ë‹ˆë‹¤ (ìµœì í™”í•˜ì§€ ì•ŠìŒ)",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "prompt": {
                                "type": "string",
                                "description": "ë¶„ì„í•  í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸"
                            },
                            "analysis_types": {
                                "type": "array",
                                "description": "ìˆ˜í–‰í•  ë¶„ì„ ìœ í˜•ë“¤",
                                "items": {
                                    "type": "string",
                                    "enum": ["clarity", "specificity", "instruction_following", "agentic_capabilities"]
                                },
                                "default": ["clarity", "specificity", "instruction_following", "agentic_capabilities"]
                            }
                        },
                        "required": ["prompt"]
                    }
                ),
                Tool(
                    name="get_prompt_suggestions",
                    description="íŠ¹ì • ë„ë©”ì¸ì´ë‚˜ ëª©ì ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë° ì œì•ˆì‚¬í•­ì„ ì œê³µí•©ë‹ˆë‹¤",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "domain": {
                                "type": "string",
                                "description": "í”„ë¡¬í”„íŠ¸ ë„ë©”ì¸ (ì˜ˆ: coding, writing, analysis, creative, customer_service)",
                                "enum": ["coding", "writing", "analysis", "creative", "customer_service", "education", "general"]
                            },
                            "task_type": {
                                "type": "string",
                                "description": "ì‘ì—… ìœ í˜• (ì˜ˆ: debug, review, generate, summarize, translate)"
                            },
                            "requirements": {
                                "type": "array",
                                "description": "íŠ¹ë³„ ìš”êµ¬ì‚¬í•­ë“¤",
                                "items": {
                                    "type": "string"
                                }
                            }
                        },
                        "required": ["domain"]
                    }
                )
            ]
        
        @self.server.call_tool()
        async def handle_call_tool(
            name: str, arguments: dict[str, Any] | None
        ) -> list[TextContent | ImageContent | EmbeddedResource]:
            """ë„êµ¬ í˜¸ì¶œì„ ì²˜ë¦¬í•©ë‹ˆë‹¤"""
            
            if arguments is None:
                arguments = {}
            
            try:
                if name == "optimize_prompt":
                    return await self._handle_optimize_prompt(arguments)
                elif name == "revise_with_feedback":
                    return await self._handle_revise_with_feedback(arguments)
                elif name == "analyze_prompt":
                    return await self._handle_analyze_prompt(arguments)
                elif name == "get_prompt_suggestions":
                    return await self._handle_get_prompt_suggestions(arguments)
                else:
                    raise ValueError(f"Unknown tool: {name}")
                    
            except Exception as e:
                logger.error(f"Error handling tool {name}: {str(e)}")
                return [
                    TextContent(
                        type="text",
                        text=f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    )
                ]
    
    async def _handle_optimize_prompt(self, arguments: dict) -> list[TextContent]:
        """í”„ë¡¬í”„íŠ¸ ìµœì í™” ë„êµ¬ ì²˜ë¦¬"""
        prompt = arguments.get("prompt", "")
        few_shot_messages = arguments.get("few_shot_messages", [])
        include_analysis = arguments.get("include_analysis", True)
        
        if not prompt:
            return [TextContent(type="text", text="í”„ë¡¬í”„íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")]
        
        # Few-shot ë©”ì‹œì§€ ë³€í™˜
        chat_messages = []
        for msg in few_shot_messages:
            role = Role.user if msg["role"] == "user" else Role.assistant
            chat_messages.append(ChatMessage(role=role, content=msg["content"]))
        
        # í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹¤í–‰
        result = await optimize_prompt_comprehensive(
            prompt=prompt,
            few_shot_messages=chat_messages if chat_messages else None
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        response = self._format_optimization_result(result, include_analysis)
        
        return [TextContent(type="text", text=response)]
    
    async def _handle_revise_with_feedback(self, arguments: dict) -> list[TextContent]:
        """í”¼ë“œë°± ê¸°ë°˜ ê°œì„  ë„êµ¬ ì²˜ë¦¬"""
        optimized_prompt = arguments.get("optimized_prompt", "")
        user_feedback = arguments.get("user_feedback", "")
        include_analysis = arguments.get("include_analysis", True)
        
        if not optimized_prompt or not user_feedback:
            return [TextContent(type="text", text="ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ì™€ í”¼ë“œë°±ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.")]
        
        # í”¼ë“œë°± ê¸°ë°˜ ê°œì„  ì‹¤í–‰
        result = await revise_prompt_with_feedback(
            optimized_prompt=optimized_prompt,
            user_feedback=user_feedback
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        response = self._format_revision_result(result, include_analysis)
        
        return [TextContent(type="text", text=response)]
    
    async def _handle_analyze_prompt(self, arguments: dict) -> list[TextContent]:
        """í”„ë¡¬í”„íŠ¸ ë¶„ì„ ë„êµ¬ ì²˜ë¦¬"""
        prompt = arguments.get("prompt", "")
        analysis_types = arguments.get("analysis_types", ["clarity", "specificity", "instruction_following", "agentic_capabilities"])
        
        if not prompt:
            return [TextContent(type="text", text="í”„ë¡¬í”„íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")]
        
        # ë¶„ì„ë§Œ ìˆ˜í–‰ (ìµœì í™” ì—†ì´)
        result = await optimize_prompt_comprehensive(
            prompt=prompt,
            few_shot_messages=None
        )
        
        # ë¶„ì„ ê²°ê³¼ë§Œ í¬ë§·íŒ…
        response = self._format_analysis_only(result, analysis_types)
        
        return [TextContent(type="text", text=response)]
    
    async def _handle_get_prompt_suggestions(self, arguments: dict) -> list[TextContent]:
        """í”„ë¡¬í”„íŠ¸ ì œì•ˆ ë„êµ¬ ì²˜ë¦¬"""
        domain = arguments.get("domain", "general")
        task_type = arguments.get("task_type", "")
        requirements = arguments.get("requirements", [])
        
        # ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
        suggestions = self._generate_prompt_suggestions(domain, task_type, requirements)
        
        return [TextContent(type="text", text=suggestions)]
    
    def _format_optimization_result(self, result: dict, include_analysis: bool) -> str:
        """ìµœì í™” ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤"""
        output = []
        
        output.append("# ğŸš€ í”„ë¡¬í”„íŠ¸ ìµœì í™” ê²°ê³¼")
        output.append("")
        
        # ìš”ì•½ ì •ë³´
        output.append("## ğŸ“Š ìµœì í™” ìš”ì•½")
        output.append(f"- **ë°œê²¬ëœ ë¬¸ì œ**: {result.get('total_issues_found', 0)}ê°œ")
        output.append(f"- **ì˜ˆìƒ ê°œì„ ìœ¨**: {result.get('estimated_improvement', 0):.0f}%")
        output.append("")
        
        # ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸
        output.append("## âœ¨ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸")
        output.append("```")
        output.append(result.get('optimized_prompt', ''))
        output.append("```")
        output.append("")
        
        if include_analysis:
            # ìƒì„¸ ë¶„ì„ ê²°ê³¼
            analysis_results = result.get('analysis_results', [])
            if analysis_results:
                output.append("## ğŸ” ë°œê²¬ëœ ë¬¸ì œì ")
                for i, issue in enumerate(analysis_results, 1):
                    output.append(f"{i}. {issue}")
                output.append("")
            
            # Few-shot ì˜ˆì œ (ìˆëŠ” ê²½ìš°)
            optimized_messages = result.get('optimized_messages', [])
            if optimized_messages:
                output.append("## ğŸ’¬ ìµœì í™”ëœ Few-shot ì˜ˆì œ")
                for i, msg in enumerate(optimized_messages, 1):
                    role = msg.get('role', 'unknown')
                    content = msg.get('content', '')
                    output.append(f"{i}. **{role}**: {content}")
                output.append("")
        
        return "\n".join(output)
    
    def _format_revision_result(self, result: dict, include_analysis: bool) -> str:
        """ê°œì„  ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤"""
        output = []
        
        output.append("# ğŸ”„ í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê°œì„  ê²°ê³¼")
        output.append("")
        
        revision_details = result.get('revision_details', {})
        changes_made = revision_details.get('changes_made', [])
        feedback_addressed = revision_details.get('feedback_addressed', [])
        
        # ìš”ì•½ ì •ë³´
        output.append("## ğŸ“Š ê°œì„  ìš”ì•½")
        output.append(f"- **ì ìš©ëœ ë³€ê²½ì‚¬í•­**: {len(changes_made)}ê°œ")
        output.append(f"- **ì²˜ë¦¬ëœ í”¼ë“œë°±**: {len(feedback_addressed)}ê°œ")
        output.append("")
        
        # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
        output.append("## âœ¨ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸")
        output.append("```")
        output.append(result.get('revised_prompt', ''))
        output.append("```")
        output.append("")
        
        if include_analysis:
            # ì ìš©ëœ ë³€ê²½ì‚¬í•­
            if changes_made:
                output.append("## ğŸ”§ ì ìš©ëœ ë³€ê²½ì‚¬í•­")
                for i, change in enumerate(changes_made, 1):
                    output.append(f"{i}. {change}")
                output.append("")
            
            # ì²˜ë¦¬ëœ í”¼ë“œë°±
            if feedback_addressed:
                output.append("## ğŸ’¬ ì²˜ë¦¬ëœ í”¼ë“œë°±")
                for i, feedback in enumerate(feedback_addressed, 1):
                    output.append(f"{i}. {feedback}")
                output.append("")
            
            # ê°œì„  ì„¤ëª…
            improvement_explanation = revision_details.get('improvement_explanation', '')
            if improvement_explanation:
                output.append("## ğŸ’¡ ê°œì„  ì„¤ëª…")
                output.append(improvement_explanation)
                output.append("")
        
        return "\n".join(output)
    
    def _format_analysis_only(self, result: dict, analysis_types: list) -> str:
        """ë¶„ì„ ê²°ê³¼ë§Œ í¬ë§·íŒ…í•©ë‹ˆë‹¤"""
        output = []
        
        output.append("# ğŸ” í”„ë¡¬í”„íŠ¸ ë¶„ì„ ê²°ê³¼")
        output.append("")
        
        # ìš”ì•½ ì •ë³´
        output.append("## ğŸ“Š ë¶„ì„ ìš”ì•½")
        output.append(f"- **ë¶„ì„ ìœ í˜•**: {', '.join(analysis_types)}")
        output.append(f"- **ë°œê²¬ëœ ë¬¸ì œ**: {result.get('total_issues_found', 0)}ê°œ")
        output.append("")
        
        # ë°œê²¬ëœ ë¬¸ì œì 
        analysis_results = result.get('analysis_results', [])
        if analysis_results:
            output.append("## âš ï¸ ë°œê²¬ëœ ë¬¸ì œì ")
            for i, issue in enumerate(analysis_results, 1):
                output.append(f"{i}. {issue}")
            output.append("")
        else:
            output.append("## âœ… ë¶„ì„ ê²°ê³¼")
            output.append("ë°œê²¬ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ê°€ ì˜ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            output.append("")
        
        return "\n".join(output)
    
    def _generate_prompt_suggestions(self, domain: str, task_type: str, requirements: list) -> str:
        """ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ ì œì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤"""
        output = []
        
        output.append(f"# ğŸ¯ {domain.title()} ë„ë©”ì¸ í”„ë¡¬í”„íŠ¸ ì œì•ˆ")
        output.append("")
        
        # ë„ë©”ì¸ë³„ í…œí”Œë¦¿
        templates = {
            "coding": {
                "base": "You are an expert software developer and code reviewer.",
                "guidelines": [
                    "Always provide detailed explanations for code changes",
                    "Include error handling and edge cases",
                    "Follow best practices and coding standards",
                    "Suggest performance improvements when applicable"
                ],
                "examples": {
                    "debug": "Analyze this code and identify any bugs, performance issues, or security vulnerabilities. Provide specific fixes with explanations.",
                    "review": "Review this code for best practices, readability, and maintainability. Suggest improvements with detailed explanations.",
                    "generate": "Generate clean, well-documented code that follows best practices. Include error handling and comments explaining the logic."
                }
            },
            "writing": {
                "base": "You are a professional writing assistant and editor.",
                "guidelines": [
                    "Maintain the original tone and style unless specified",
                    "Provide specific suggestions for improvement",
                    "Explain grammar and style recommendations",
                    "Consider the target audience"
                ],
                "examples": {
                    "edit": "Review this text for grammar, clarity, and style. Provide specific suggestions for improvement while maintaining the original tone.",
                    "generate": "Write [type of content] that is engaging, well-structured, and appropriate for [target audience]. Focus on clarity and impact.",
                    "summarize": "Create a concise summary that captures the key points and main arguments while maintaining the essential meaning."
                }
            },
            "analysis": {
                "base": "You are an expert analyst with deep analytical thinking skills.",
                "guidelines": [
                    "Provide structured, logical analysis",
                    "Support conclusions with evidence",
                    "Consider multiple perspectives",
                    "Identify patterns and trends"
                ],
                "examples": {
                    "analyze": "Analyze this data/situation thoroughly. Identify key patterns, trends, and insights. Provide actionable recommendations based on your findings.",
                    "compare": "Compare and contrast these options/concepts. Analyze the strengths, weaknesses, and implications of each approach.",
                    "evaluate": "Evaluate this proposal/solution critically. Consider feasibility, risks, benefits, and potential outcomes."
                }
            }
        }
        
        # ì„ íƒëœ ë„ë©”ì¸ì˜ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
        template = templates.get(domain, {
            "base": "You are a helpful AI assistant.",
            "guidelines": [
                "Provide clear and accurate information",
                "Be helpful and responsive to user needs",
                "Ask clarifying questions when needed"
            ],
            "examples": {}
        })
        
        # ê¸°ë³¸ í…œí”Œë¦¿
        output.append("## ğŸ—ï¸ ê¸°ë³¸ í…œí”Œë¦¿")
        output.append("```")
        output.append(template["base"])
        output.append("")
        output.append("# Guidelines:")
        for guideline in template["guidelines"]:
            output.append(f"- {guideline}")
        
        # ìš”êµ¬ì‚¬í•­ ì¶”ê°€
        if requirements:
            output.append("")
            output.append("# Additional Requirements:")
            for req in requirements:
                output.append(f"- {req}")
        
        output.append("")
        output.append("Please keep going until the task is completely resolved, before ending your turn.")
        output.append("Plan extensively before taking action, and reflect on the outcomes of your actions.")
        output.append("```")
        output.append("")
        
        # ì‘ì—… ìœ í˜•ë³„ ì˜ˆì œ
        if task_type and task_type in template["examples"]:
            output.append(f"## ğŸ’¡ '{task_type}' ì‘ì—…ì„ ìœ„í•œ íŠ¹í™” í”„ë¡¬í”„íŠ¸")
            output.append("```")
            output.append(template["base"])
            output.append("")
            output.append(template["examples"][task_type])
            output.append("```")
            output.append("")
        
        # ì¶”ê°€ ì œì•ˆ
        output.append("## ğŸ“ ì¶”ê°€ ê°œì„  ì œì•ˆ")
        output.append("1. **ëª…í™•í•œ ì¶œë ¥ í˜•ì‹ ì§€ì •**: ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹(JSON, ë§ˆí¬ë‹¤ìš´, êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ë“±)ì„ ëª…ì‹œí•˜ì„¸ìš”")
        output.append("2. **ì˜ˆì œ ì œê³µ**: Few-shot ì˜ˆì œë¥¼ ì¶”ê°€í•˜ì—¬ ê¸°ëŒ€í•˜ëŠ” ì‘ë‹µ ìŠ¤íƒ€ì¼ì„ ëª…í™•íˆ í•˜ì„¸ìš”")
        output.append("3. **ì œì•½ì‚¬í•­ ëª…ì‹œ**: ê¸¸ì´ ì œí•œ, ì‚¬ìš©í•  ì–¸ì–´, í”¼í•´ì•¼ í•  ë‚´ìš© ë“±ì„ ëª…í™•íˆ í•˜ì„¸ìš”")
        output.append("4. **ì»¨í…ìŠ¤íŠ¸ ì œê³µ**: ì‘ì—…ì˜ ë°°ê²½, ëª©ì , ëŒ€ìƒ ë…ì ë“±ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”")
        output.append("")
        
        return "\n".join(output)
    
    async def run(self):
        """MCP ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤"""
        async with stdio_server() as (read_stream, write_stream):
            await self.server.run(
                read_stream,
                write_stream,
                InitializationOptions(
                    server_name="prompt-optimizer",
                    server_version="1.0.0",
                    capabilities=self.server.get_capabilities(
                        notification_options=None,
                        experimental_capabilities=None,
                    ),
                ),
            )

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    server = PromptOptimizerMCPServer()
    await server.run()

if __name__ == "__main__":
    asyncio.run(main()) 